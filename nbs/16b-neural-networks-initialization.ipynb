{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network 102 - Initialization Neural Network\n",
    "\n",
    "เปรียบเทียบการ Initialize Weight แบบต่าง ๆ ว่าจะมีผลต่อ Gradient อย่างไร แบบไหนช่วยลดปัญหา Vanishing Gradient และ Exploding Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เคสนี้เราจะใช้ MNIST Dataset เหมือนเดิม"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train, y_train, x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ดาวน์โหลดชุดข้อมูลมาใส่ x, y ทั้ง Training Set และ Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. เตรียมข้อมูล"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "หา mean และ standard deviation ของข้อมูล Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304), tensor(0.3073))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean, train_std = x_train.mean(), x_train.std()\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เนื่องจากทุกอย่างมาจากข้อมูลคนละแหล่ง เราไม่ทราบว่าอันไหนสำคัญกว่าอันไหน เราจึง Normalize ข้อมูลทุกอย่างให้อยู่ใน Scale เดียวกันให้หมด โดย mean = 0, std = 1 เท่ากันหมด แล้วให้โมเดลเรียนรู้เอง จากข้อมูลตัวอย่างว่าอันไหน สำคัญเท่าไร สัมพันธ์กันอย่างไร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize คือการทำให้ข้อมูล มี mean = 0 และ standard deviation (std) = 1 ด้วยการ ลบด้วย mean หารด้วย std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = data, m = mean, s = standard deviation\n",
    "def normalize(x, m, s): \n",
    "    return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize ข้อมูล Validation Set ด้วย mean, std ของ Training Set เพื่อปรับให้เป็น Scale เดียวกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ลองดูค่า mean, std หลังจาก Normalize เรียบร้อยแล้ว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6999e-06), tensor(1.))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean_after, train_std_after = x_train.mean(), x_train.std()\n",
    "train_mean_after, train_std_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ได้ mean เป็นเลขจุดทศนิยมน้อยมาก ๆ ใกล้เคียง 0 และ std ใกล้เคียง 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = จำนวน Record, m จำนวน Feature, c = จำนวน class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "แปลงจาก Long เป็น Float ก่อนส่งให้ Loss Function เนื่องจากเราใช้ Mse แทน Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = y_train.float(), y_valid.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราจะสร้าง 4 Hidden Layers Neural Networks ที่มี 100 Neuron ในแต่ละ Hidden Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nh = number of hidden\n",
    "nh = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    def forward(self, inp):\n",
    "        raise Exception('Not implemented')\n",
    "    def backward(self):\n",
    "        self.bwd(self.out, *self.args)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Module):\n",
    "    def forward(self, inp):\n",
    "        return inp.clamp_min(0.) - 0.5\n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = (inp>0).float()*out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Module):\n",
    "    def forward(self, inp):\n",
    "        return 1/(1 + torch.exp(-inp)) \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = (self.forward(inp) * (1 - self.forward(inp))) * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b):\n",
    "        self.w, self.b = w, b\n",
    "    def forward(self, inp):\n",
    "        return inp @ self.w + self.b\n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g = inp.squeeze(-1).t() @ out.g\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse(Module):\n",
    "    def forward(self, inp, targ):\n",
    "        return (inp.squeeze(-1) - targ).pow(2).mean()\n",
    "    def bwd(self, out, inp, targ):\n",
    "        inp.g = 2. * (inp.squeeze(-1) - targ).unsqueeze(-1) / inp.shape[0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สร้างโมเดล ที่มี 4 Hidden Layer และ Activation หลายแบบให้เลือก ใน Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2), Relu(), Lin(w3, b3), Relu(), Lin(w4, b4)]\n",
    "#         self.layers = [Lin(w1, b1), Sigmoid(), Lin(w2, b2), Sigmoid(), Lin(w3, b3), Sigmoid(), Lin(w4, b4)]\n",
    "#         self.layers = [Lin(w1, b1), Lin(w2, b2), Lin(w3, b3), Lin(w4, b4)]\n",
    "        self.loss = Mse()\n",
    "    def __call__(self, x, targ):\n",
    "#         set_trace()\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return self.loss(x, targ), x\n",
    "    def backward(self):\n",
    "        self.loss.backward()        \n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราจะลอง Initinalize กำหนดค่าเริ่มต้น Weight และ Bias แบบต่าง ๆ แล้วเราจะใช้ข้อมูลเดียวกัน รันผ่านโมเดล แล้ว Backpropagate เพื่อเปรียบเทียบ ว่า Gradient เป็นอย่างไร  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Normal Distribution (Gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "กำหนดค่าเริ่มต้นของ Weight และ Bias ด้วยค่า Random แบบ Normal Distribution (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(m, nh)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh, nh)\n",
    "b2 = torch.zeros(nh)\n",
    "w3 = torch.randn(nh, nh)\n",
    "b3 = torch.zeros(nh)\n",
    "w4 = torch.randn(nh, 1)\n",
    "b4 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ลองดูค่า mean, std ของ Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0006), tensor(1.0012))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(), w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0190), tensor(1.0068))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.mean(), w2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0011), tensor(0.9909))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3.mean(), w3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0879), tensor(1.0427))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4.mean(), w4.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight ดูดีมาก ใกล้เคียง mean = 0, std = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ลองสมมติว่าเป็น Layer แรก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.1000), tensor(28.5732))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = x_train @ w1\n",
    "a1.mean(), a1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ลองสมมติว่าเป็น Layer แรก + ReLU Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(11.3143), tensor(16.9981))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = (x_train @ w1).clamp(0.)-0.5\n",
    "z1.mean(), z1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราได้ Activation ของ Layer แรก ที่ไม่ใกล้เคียง mean = 0, std = 1 เลย อาจจะมีปัญหาตอนเทรนได้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สร้างโมเดล รัน forward และ backward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g,b1.g,w2.g,b2.g,w3.g,b3.g,w4.g,b4.g = [None]*8\n",
    "model = Model()\n",
    "loss, yhat = model(x_train, y_train)\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตรวจเช็ค Mean และ Standard Deviation ของ Gradient ของ Weight ของแต่ละ Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6752871.5000), tensor(7748565.5000))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4.g.mean(), w4.g.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(50369.2070), tensor(899103.5000))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3.g.mean(), w3.g.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(43154.5938), tensor(557012.8125))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.g.mean(), w2.g.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(515.9893), tensor(157482.1406))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.g.mean(), w1.g.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient ที่เราต้องการคือประมาณ mean = 0, std = 1 แต่นี่ไม่ได้ใกล้เคียงเลย ถ้าเป็นแบบนี้จะทำให้เกิดปัญหา Exploding Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Kaiming Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "กำหนดค่าเริ่มต้นของ Weight และ Bias ด้วย Kaiming Init เวอร์ชันง่าย * math.sqrt(1./m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(m, nh) * math.sqrt(1./m)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh, nh)* math.sqrt(1./nh)\n",
    "b2 = torch.zeros(nh)\n",
    "w3 = torch.randn(nh, nh) * math.sqrt(1./nh)\n",
    "b3 = torch.zeros(nh)\n",
    "w4 = torch.randn(nh, 1) * math.sqrt(1./nh)\n",
    "b4 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ลองดูค่า mean, std ของ Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.0969e-05), tensor(0.0358))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(), w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0002), tensor(0.0988))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.mean(), w2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0004), tensor(0.0995))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3.mean(), w3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0047), tensor(0.1064))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4.mean(), w4.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight จะ mean, std เป็นอย่างไรเรายังไม่สนใจ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ลองสมมติว่าเป็น Layer แรก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0260), tensor(0.9986))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = x_train @ w1\n",
    "a1.mean(), a1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ลองสมมติว่าเป็น Layer แรก + ReLU Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0915), tensor(0.5835))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = (x_train @ w1).clamp(0.)-0.5\n",
    "z1.mean(), z1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราได้ Activation ของ Layer แรก ที่ใกล้เคียง mean = 0, std = 1 มากขึ้น"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สร้างโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g,b1.g,w2.g,b2.g,w3.g,b3.g,w4.g,b4.g = [None]*8\n",
    "model = Model()\n",
    "loss, yhat = model(x_train, y_train)\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตรวจเช็ค Mean และ Standard Deviation ของ Gradient ของ Weight ของแต่ละ Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.6649), tensor(1.3136))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4.g.mean(), w4.g.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0009), tensor(0.1455))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3.g.mean(), w3.g.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0045), tensor(0.0782))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.g.mean(), w2.g.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0001), tensor(0.0831))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.g.mean(), w1.g.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราได้ Gradient ที่ใกล้เคียง mean = 0, std = 1 มากขึ้น"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Kaiming Initialization 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "กำหนดค่าเริ่มต้นของ Weight และ Bias ด้วย Kaiming Init เวอร์ชันปรับปรุง เปลี่ยนจาก 1./m เป็น 2./m เพิ่มเป็น 2 เท่า เนื่องจาก ReLU Function ข้อมูลที่ติดลบ จะถูกทำให้เป็น 0 ทำข้อมูลหายไปครึ่งนึง "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(m, nh) * math.sqrt(2./m)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh, nh)* math.sqrt(2./nh)\n",
    "b2 = torch.zeros(nh)\n",
    "w3 = torch.randn(nh, nh) * math.sqrt(2./nh)\n",
    "b3 = torch.zeros(nh)\n",
    "w4 = torch.randn(nh, 1) * math.sqrt(2./nh)\n",
    "b4 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ลองดูค่า mean, std ของ Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0001), tensor(0.0508))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(), w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0011), tensor(0.1402))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.mean(), w2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0019), tensor(0.1424))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3.mean(), w3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0125), tensor(0.1375))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4.mean(), w4.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight จะ mean, std เป็นอย่างไรเรายังไม่สนใจ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ลองสมมติว่าเป็น Layer แรก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0492), tensor(1.3743))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = x_train @ w1\n",
    "a1.mean(), a1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ลองสมมติว่าเป็น Layer แรก + ReLU Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0702), tensor(0.8312))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = (x_train @ w1).clamp(0.)-0.5\n",
    "z1.mean(), z1.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราได้ Activation ของ Layer แรก ที่ใกล้เคียง mean = 0, std = 1 มากขึ้นอีก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สร้างโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g,b1.g,w2.g,b2.g,w3.g,b3.g,w4.g,b4.g = [None]*8\n",
    "model = Model()\n",
    "loss, yhat = model(x_train, y_train)\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตรวจเช็ค Mean และ Standard Deviation ของ Gradient ของ Weight ของแต่ละ Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6593), tensor(2.1650))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4.g.mean(), w4.g.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0021), tensor(0.2243))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3.g.mean(), w3.g.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0003), tensor(0.2305))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.g.mean(), w2.g.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0011), tensor(0.2433))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.g.mean(), w1.g.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราได้ Gradient ที่ใกล้เคียง mean = 0, std = 1 มากขึ้นอีก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. สรุป"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. วิธีการ Initialize ค่าของ Weight มีความสำคัญอย่างมาก ต่อ Gradient ซึ่งมีผลต่อการเทรน Neural Network\n",
    "1. ยิ่ง Deep Neural Network ยิ่ง Deep มากขึ้นเท่าไร ยิ่งส่งผลต่อ Gradient เป็นทวีคูณ ถ้าน้อยก็จะน้อยไปเรื่อย ๆ จนเป็น 0 ถ้ามากก็จะมากจนเกินรับไหว เป็น Not a number (nan)\n",
    "1. ในการเทรน Neural Network แล้ว Gradient เป็นส่วนสำคัญที่สุด ที่ช่วยให้เทรนสำเร็จ ได้โมเดลที่ดี จน Yann LeCun เสนอให้เรียกว่า Differentiable Programming แทน Deep Learning (Gradient คือ Diff ของหลายตัวแปร เช่น Matrix, Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://course.fast.ai/videos/?lesson=8\n",
    "* https://arxiv.org/abs/1502.01852\n",
    "* http://proceedings.mlr.press/v9/glorot10a.html\n",
    "* https://deeplearning.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
