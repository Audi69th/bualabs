{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ในการเทรน Neural Network แล้ว Operation ส่วนใหญ่ก็คือ การคุณเมตริกซ์ Activation ของ Layer ก่อนหน้า กับ Weight ของ Layer นั้น \n",
    "\n",
    "เราได้ Normalize ข้อมูล Input ให้มีขนาด mean = 0, std = 1 เรียบร้อยแล้ว แล้ว Weight เราควร Initialize อย่างไร ให้ไม่เกิดปัญหา Vanishing Gradient และ Exploding Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Vanishing Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สมมติ Weight เรา Inital ไว้น้อยเกินไป จะทำให้เกิด Vanishing Gradient คือ Gradient น้อยลงจนโมเดลเทรนไม่ไปไหน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100, 100)\n",
    "a = torch.randn(100, 100) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0001), tensor(1.0025))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0001), tensor(0.0100))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean(), a.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00017507371376268566, 0.10167848318815231\n",
      "-7.372301479335874e-05, 0.010261043906211853\n",
      "-2.8780448246834567e-06, 0.0010143351973965764\n",
      "-1.6876927588782564e-07, 9.777984087122604e-05\n",
      "3.359240352551751e-08, 9.540214705339167e-06\n",
      "3.691448258180685e-09, 9.169621080218349e-07\n",
      "2.2091392604117743e-10, 9.000610390330621e-08\n",
      "2.3500966797596057e-11, 8.619646330032538e-09\n",
      "-4.689652312317438e-12, 8.395186212872829e-10\n",
      "-6.89078297460427e-13, 8.345434066026058e-11\n",
      "-9.060880165742344e-14, 8.246623002527986e-12\n",
      "-1.074634681236383e-14, 8.031314328860173e-13\n",
      "4.0925230644648974e-17, 7.924113839055669e-14\n",
      "-4.940155883099421e-17, 7.702458530473195e-15\n",
      "9.769065072797198e-18, 7.462395734815052e-16\n",
      "5.931241196656489e-19, 7.295576169273564e-17\n",
      "5.596971565763158e-20, 7.080672660898817e-18\n",
      "1.8003073083301636e-21, 6.833727298200579e-19\n",
      "-3.273794213683821e-22, 6.744837177105923e-20\n",
      "-8.420163251670666e-24, 6.68612270169243e-21\n",
      "1.02225891327365e-24, 6.659254275965445e-22\n",
      "-3.2391686335025807e-25, 6.588797889967663e-23\n",
      "-5.0923396563002284e-26, 6.4721828700454665e-24\n",
      "-6.53037777381013e-27, 6.432227854056927e-25\n",
      "-9.780677296315138e-28, 6.331511640356548e-26\n",
      "7.020566095201332e-30, 6.388391284962103e-27\n",
      "1.3626370011342144e-30, 6.436210873626775e-28\n",
      "9.03973681573308e-31, 6.482957045236942e-29\n",
      "1.1554616936450092e-31, 6.438635077758961e-30\n",
      "6.993461846211132e-33, 6.444367540529955e-31\n",
      "4.8742520697094065e-34, 6.369970385516978e-32\n",
      "-3.401159168663009e-35, 6.433355685775605e-33\n",
      "-9.800230712218542e-36, 6.495972800475969e-34\n",
      "-9.593523359663178e-37, 6.533821193096303e-35\n",
      "-9.67002775379044e-38, 6.549985962335662e-36\n",
      "-6.081086026171691e-39, 6.527537026412526e-37\n",
      "2.812125758207043e-41, 6.581385451176337e-38\n",
      "2.2336697521337584e-42, 6.633828205424615e-39\n",
      "5.640226318907389e-42, 6.712401812916236e-40\n",
      "8.169570047013684e-43, 6.708856527801494e-41\n",
      "7.286752014489049e-44, 6.74304821033102e-42\n",
      "8.407790785948902e-45, 6.6982066594726256e-43\n",
      "0.0, 6.726232628759122e-44\n",
      "-0.0, 7.006492321624085e-45\n",
      "0.0, 0.0\n",
      "0.0, 0.0\n",
      "0.0, 0.0\n",
      "0.0, 0.0\n",
      "0.0, 0.0\n",
      "0.0, 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    x = x @ a \n",
    "    print(f'{x.mean()}, {x.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient น้อยลง ๆ ๆ จนหายไปหมด กลายเป็น 0 เรียกว่า Vanishing Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploding Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สมมติ Weight เรา Inital ไว้มากเกินไป จะทำให้เกิด Exploding Gradient คือ Gradient มากจนโมเดล Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100, 100)\n",
    "a = torch.randn(100, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0048), tensor(0.9941))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0006), tensor(0.9968))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean(), a.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.13390818238258362, 9.991456985473633\n",
      "-0.05380872264504433, 100.56512451171875\n",
      "6.502710342407227, 1014.0548706054688\n",
      "99.55369567871094, 10225.2802734375\n",
      "-1185.7562255859375, 102960.796875\n",
      "-3255.572509765625, 1034719.5\n",
      "33751.78515625, 10397952.0\n",
      "370168.03125, 106319144.0\n",
      "8326245.5, 1092690560.0\n",
      "96204656.0, 11263079424.0\n",
      "-327059072.0, 115864281088.0\n",
      "-13615388672.0, 1202106531840.0\n",
      "-82196611072.0, 12214876504064.0\n",
      "669934354432.0, 125522004672512.0\n",
      "7082630709248.0, 1299222775201792.0\n",
      "5463895179264.0, 1.3444827110703104e+16\n",
      "-314454688399360.0, 1.3723501983485133e+17\n",
      "-6957735350370304.0, 1.3998246746442957e+18\n",
      "-1.894995405570048e+16, 1.419161978056527e+19\n",
      "8.099675413875261e+17, 1.4332929234869368e+20\n",
      "6.592233015005413e+18, 1.4394997633827555e+21\n",
      "-2.6162531737255543e+19, 1.4556200323314585e+22\n",
      "-7.762676644775754e+20, 1.439431145412933e+23\n",
      "-3.3720249035224085e+21, 1.43265081404434e+24\n",
      "3.144139440972736e+22, 1.406440296558608e+25\n",
      "3.623719118380136e+23, 1.3843241030953261e+26\n",
      "1.1274474157321825e+24, 1.3587908578182603e+27\n",
      "-2.792303711271595e+25, 1.3388656293431358e+28\n",
      "-3.810197124517596e+26, 1.299153431477589e+29\n",
      "1.3866594608950578e+27, 1.2807224128842675e+30\n",
      "4.210666434595284e+28, 1.2404012913615337e+31\n",
      "9.73104910112238e+28, 1.2152968586839983e+32\n",
      "-2.5453757837742173e+30, 1.1785490921881396e+33\n",
      "-3.188775413701934e+31, 1.1521225695300077e+34\n",
      "-3.8886767305535616e+30, 1.1179491852279332e+35\n",
      "2.878776020451453e+33, 1.1084397061799149e+36\n",
      "inf, 1.0893376694326657e+37\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n",
      "nan, nan\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    x = x @ a \n",
    "    print(f'{x.mean()}, {x.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient มากขึ้น ๆ ๆ ๆ จนเกินค่ามากที่สุด ที่ระบบรับไหว เหมือนกับระเบิดออก กลายเป็น Infinity (inf) หรือ Not a number (nan) เรียกว่า Exploding Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Kaiming Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การ Initialize Weight ที่เหมาะสม ด้วย Kaiming Initialization จะช่วยให้เราเทรนโมเดล เร็วขึ้น และเทรนได้นานขึ้นตามที่เราต้องการโดยไม่ Error ไปเสียก่อน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = torch.randn(100, 100)\n",
    "a = torch.randn(100, 100) * math.sqrt(1./100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ในเคสนี้ เป็น Kaiming Initialization เวอร์ชัน สำหรับไม่มี Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0041), tensor(0.9940))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0009), tensor(0.1007))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean(), a.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01355910673737526, 1.009394884109497\n",
      "-0.0009019583812914789, 1.008618950843811\n",
      "0.006854343228042126, 1.035135269165039\n",
      "0.005343644414097071, 1.0571950674057007\n",
      "-0.01608518324792385, 1.0883299112319946\n",
      "-0.03656657040119171, 1.1212023496627808\n",
      "0.011612932197749615, 1.150809407234192\n",
      "-0.007006821222603321, 1.170104742050171\n",
      "-0.01744045503437519, 1.1924595832824707\n",
      "0.04205748066306114, 1.2023160457611084\n",
      "0.007699768058955669, 1.208798885345459\n",
      "0.0028597936034202576, 1.2344635725021362\n",
      "-0.012984923087060452, 1.250748634338379\n",
      "0.0026043711695820093, 1.2699295282363892\n",
      "-0.008521312847733498, 1.2942026853561401\n",
      "-0.03892156854271889, 1.3185118436813354\n",
      "0.022261012345552444, 1.3530927896499634\n",
      "0.01013812143355608, 1.3929109573364258\n",
      "-0.006325617432594299, 1.4162572622299194\n",
      "0.026290105655789375, 1.4530174732208252\n",
      "0.027532892301678658, 1.4988577365875244\n",
      "-0.035421572625637054, 1.5125532150268555\n",
      "-2.3201537260320038e-05, 1.557770013809204\n",
      "0.003481278195977211, 1.595447063446045\n",
      "-0.06150686740875244, 1.637009620666504\n",
      "0.018829915672540665, 1.7182097434997559\n",
      "0.014152048155665398, 1.764128565788269\n",
      "-0.01075518038123846, 1.8089364767074585\n",
      "0.03307539224624634, 1.8812752962112427\n",
      "0.01662435382604599, 1.9323909282684326\n",
      "-0.005312175955623388, 1.9792102575302124\n",
      "-0.011570210568606853, 2.052011489868164\n",
      "-0.018291903659701347, 2.0984373092651367\n",
      "-0.022761862725019455, 2.197435140609741\n",
      "-0.0018902012379840016, 2.31196928024292\n",
      "-0.007784965448081493, 2.3666162490844727\n",
      "0.02261563017964363, 2.482487440109253\n",
      "0.0278328787535429, 2.575256586074829\n",
      "0.009414051659405231, 2.645249128341675\n",
      "0.018474560230970383, 2.778390884399414\n",
      "-0.025984350591897964, 2.8852901458740234\n",
      "-0.005247613415122032, 3.008986234664917\n",
      "-0.02312774583697319, 3.196171522140503\n",
      "-0.044793449342250824, 3.3447742462158203\n",
      "0.03486620634794235, 3.491058111190796\n",
      "0.009086054749786854, 3.7076737880706787\n",
      "-0.012383528985083103, 3.8368442058563232\n",
      "0.07430160790681839, 3.9988150596618652\n",
      "0.0030145645141601562, 4.242761611938477\n",
      "-0.06443119794130325, 4.384275913238525\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    x = x @ a \n",
    "    print(f'{x.mean()}, {x.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เทรนยังไง ก็ยังใกล้เคียง mean = 0, std = 1 สามารถเทรนไปได้อีกยาว ๆ ไม่มี Vanishing Gradient และ Exploding Gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Kaiming Initialization and ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การ Initialize Weight ที่เหมาะสม ด้วย Kaiming Initialization จะช่วยให้เราเทรนโมเดล เร็วขึ้น และเทรนได้นานขึ้นตามที่เราต้องการโดยไม่ Error ไปเสียก่อน "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = torch.randn(100, 100)\n",
    "a = torch.randn(100, 100) * math.sqrt(2./100.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ในเคสนี้ เป็น Kaiming Initialization เวอร์ชัน รองรับ ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0201), tensor(1.0026))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0009), tensor(0.1421))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean(), a.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เพิ่ม ReLU Activation Function หลังจากที่ คุณเมตริกซ์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05886748060584068, 0.8281500339508057\n",
      "-0.033054009079933167, 0.6885173916816711\n",
      "-0.10326369851827621, 0.5854166746139526\n",
      "-0.1523090898990631, 0.5158868432044983\n",
      "-0.18360678851604462, 0.46670782566070557\n",
      "-0.2053983211517334, 0.43096715211868286\n",
      "-0.22285041213035583, 0.41442015767097473\n",
      "-0.2292095273733139, 0.40878817439079285\n",
      "-0.23003438115119934, 0.40389448404312134\n",
      "-0.2422867864370346, 0.38915613293647766\n",
      "-0.24782265722751617, 0.384470671415329\n",
      "-0.24618056416511536, 0.3883412778377533\n",
      "-0.2510676383972168, 0.3791261315345764\n",
      "-0.2583562135696411, 0.3744102120399475\n",
      "-0.25615394115448, 0.3753649592399597\n",
      "-0.2604292333126068, 0.36984989047050476\n",
      "-0.2650303542613983, 0.3634847402572632\n",
      "-0.2675199508666992, 0.3619166314601898\n",
      "-0.2693164646625519, 0.3584318161010742\n",
      "-0.2713205814361572, 0.3555430769920349\n",
      "-0.2736847996711731, 0.3526526093482971\n",
      "-0.27716296911239624, 0.34966370463371277\n",
      "-0.2775050103664398, 0.3492511808872223\n",
      "-0.27866366505622864, 0.34820398688316345\n",
      "-0.28135573863983154, 0.3452775180339813\n",
      "-0.28112712502479553, 0.34543952345848083\n",
      "-0.28221356868743896, 0.34388619661331177\n",
      "-0.28263363242149353, 0.34272679686546326\n",
      "-0.28313174843788147, 0.3422655463218689\n",
      "-0.2834358215332031, 0.3416379988193512\n",
      "-0.2825915515422821, 0.3423434793949127\n",
      "-0.2820292115211487, 0.3422669768333435\n",
      "-0.28415390849113464, 0.3398551940917969\n",
      "-0.28303757309913635, 0.3424292206764221\n",
      "-0.2837241590023041, 0.34237298369407654\n",
      "-0.28396153450012207, 0.34192636609077454\n",
      "-0.2840702533721924, 0.34198322892189026\n",
      "-0.2836642265319824, 0.3424299955368042\n",
      "-0.28417396545410156, 0.3423575162887573\n",
      "-0.28401267528533936, 0.342038631439209\n",
      "-0.28392237424850464, 0.3415791988372803\n",
      "-0.28328704833984375, 0.34238967299461365\n",
      "-0.2839219868183136, 0.34115758538246155\n",
      "-0.2837132215499878, 0.34232258796691895\n",
      "-0.2834554612636566, 0.34281161427497864\n",
      "-0.283578097820282, 0.34269610047340393\n",
      "-0.28446874022483826, 0.3419050872325897\n",
      "-0.283626526594162, 0.3434770107269287\n",
      "-0.28337380290031433, 0.34336596727371216\n",
      "-0.283939927816391, 0.3424307405948639\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    x = x @ a \n",
    "    x.clamp_(0.).sub_(0.5)\n",
    "    print(f'{x.mean()}, {x.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. สรุป"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialization เป็นวิธีง่าย ๆ ที่คนมองข้ามไป ที่จะมาช่วยแก้ปัญหา Vanishing Gradient และ Exploding Gradient\n",
    "1. อันนี้เป็นตัวอย่างง่าย ๆ ให้พอเห็นภาพ แต่ Neural Network จริง ๆ จะซับซ้อนกว่านี้ และมี Activation Function มาคั่น ทำให้พฤติกรรมของ Gradient เปลี่ยนไปอีก\n",
    "1. ยังมีอีกหลายเทคนิค ที่มาช่วยคุมให้ไม่เกิดการ Vanishing Gradient และ Exploding Gradient เช่น เปลี่ยนจาก Sigmoid Activation Function เป็น ReLU Activation Function, Batch Normalization, LSTM, Residual Neural Network, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://course.fast.ai/videos/?lesson=8\n",
    "* https://arxiv.org/abs/1502.01852\n",
    "* http://proceedings.mlr.press/v9/glorot10a.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
