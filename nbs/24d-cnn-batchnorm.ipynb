{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "24d-cnn-batchnorm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMqoaV151MRo",
        "colab_type": "text"
      },
      "source": [
        "จากใน ep ก่อน ที่เราได้เรียนรู้การทำ [Normalization ข้อมูล Input](https://www.bualabs.com/archives/2100/what-is-normalization-feature-scaling-rescaling-normalization-standardization-feedforward-train-machine-learning-preprocessing-ep-2/) ให้มี Mean=0, Std=1 เท่ากันในทุก Feature ว่ามีประโยชน์ในการเทรน Machine Learning อย่างไร คำถามก็คือ แล้วทำไมเราไม่ทำแบบเดียวกันใน Hidden Layer ของ Deep Neural Network ด้วยล่ะ \n",
        "\n",
        "ไอเดียนี้ เรียกว่า BatchNorm มีประโยชน์หลายอย่าง ในการเทรน Machine Learning เช่น \n",
        "\n",
        "* ช่วยให้ [Gradient](https://www.bualabs.com/archives/631/what-is-gradient-descent-in-deep-learning-what-is-stochastic-gradient-descent-sgd-optimization-ep-1/) ไหลได้ดีขึ้น\n",
        "* ทำให้เราสามารถใช้ [Learning Rate](https://www.bualabs.com/archives/618/learning-rate-deep-learning-how-to-hyperparameter-tuning-ep-1/) ได้มากกว่าเดิม\n",
        "* ลดความจำเป็นในการ [Intialize](https://www.bualabs.com/archives/1789/what-is-vanishing-gradient-problem-fix-vanishing-gradient-problem-with-xavier-initialization-kaiming-initialization-neural-network-ep-2/) ที่ซับซ้อน\n",
        "* เป็นวิธีการ [Regularization](https://www.bualabs.com/archives/1170/what-is-data-augmentation-benefits-data-augmentaion-deep-learning-training-model-deep-neural-network-regularization-ep-1/) แบบหนึ่ง ในตัวเอง\n",
        "* ถ้าใช้ BatchNorm ร่วมกับ [Dropout](https://www.bualabs.com/archives/1533/what-is-dropout-benefits-dropout-reduce-overfit-deep-learning-training-model-deep-neural-network-regularization-ep-2/) ทำให้ลดความจำเป็นที่ต้องใช้ L2 Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtZHS0F99IEG",
        "colab_type": "text"
      },
      "source": [
        "# 0. Magic Commands\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ot4A4y9IEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH68Y5_N9IE7",
        "colab_type": "text"
      },
      "source": [
        "# 1. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt6egYhb9IFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import accuracy\n",
        "import torch.nn.init as init\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.functional\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOnc0IC39IFP",
        "colab_type": "text"
      },
      "source": [
        "# 2. ข้อมูล\n",
        "\n",
        "ใช้ชุดข้อมูล Dataset [MNIST](https://www.bualabs.com/archives/2215/what-is-mnist/) ตัวเลขอารบิคเขียนด้วยลายมือ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-KaJsQU9IFT",
        "colab_type": "code",
        "outputId": "82f7910f-8ef4-451c-a9bb-5df82f431657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Small Dataset for quick test\n",
        "# path = untar_data(URLs.MNIST_SAMPLE)\n",
        "\n",
        "# Full Dataset\n",
        "path = untar_data(URLs.MNIST)\n",
        "path"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.fastai/data/mnist_png')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxuzl8gi9IGi",
        "colab_type": "text"
      },
      "source": [
        "# 3. เตรียมข้อมูล\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVO9Gpau9IGk",
        "colab_type": "text"
      },
      "source": [
        "1. สำหรับข้อมูลประเภทตัวเลข เราไม่สามารถ flip ซ้าย ขวา ขึ้น ลง ได้ จะทำให้ผิดความหมายไป จึงต้องใช้ get_transforms(do_flip=False)\n",
        "2. เคสนี้ label คือชื่อ Folder ที่บรรจุไฟล์อยู่ เราสามารถ ใช้ ImageDataBunch.from_folder ได้เลย\n",
        "3. num_workers คือ จำนวน CPU Core ที่ต้องการใช้"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5Emr0xh9IGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsize = 64\n",
        "max_lr = 3e-2\n",
        "wd = 1e-1\n",
        "np.random.seed(0)\n",
        "transform = get_transforms(do_flip=False)\n",
        "\n",
        "databunch = ImageDataBunch.from_folder(path, train='training', valid_pct=0.2, size=28, \n",
        "                                       ds_tfms=transform, bs=batchsize, num_workers=8).normalize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfDAvA8m9IGr",
        "colab_type": "text"
      },
      "source": [
        "## สำรวจข้อมูล ##\n",
        "\n",
        "ลองดูข้อมูล Batch แรก ด้วย show_batch สั่งให้แสดง รูป พร้อม label ไว้บนรูป แสดง 3 แถว (rows) ในกรอบขนาด 10 x 10 นิ้ว (figsize)\n",
        "\n",
        "*เราสามารถรัน cell นี้หลายครั้ง เพื่อเรียกดู batch ต่อ ๆ ไป ได้เรื่อย ๆ เป็นการสำรวจข้อมูล*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BqVtZBy9IGt",
        "colab_type": "code",
        "outputId": "4d01eadd-5736-4ab4-fa97-d1297971bdfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "databunch.show_batch(rows=3, figsize=(10, 10))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAroAAALICAYAAACQF1PTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmQXmWZ8P/7ZCfpbCSZJGSBECBA\nAgmGLRAlA7KIigugSIlA4agjIy7jVq/bOJQrU6POqzDjTx1QptwYBAQXdkG2gIEAIRCykIDZ907S\nnaX7/P5Q33HguQ6dTtJP992fTxU1er510nckp5+LU/Q1RVmWCQAActOj3gcAAIB9waALAECWDLoA\nAGTJoAsAQJYMugAAZMmgCwBAlgy6AABkyaDbDRRF8Q9FUTxWFMX2oiiurfd5gFdXFMWhRVE0F0Vx\nfb3PAtRWFMX1RVGsKIpic1EUC4qieG+9z8T/Vvh/GJG/oijenlJqTSmdmVLaryzLS+p7IuDVFEVx\ne0ppv5TS0rIs313v8wCvVBTF5JTSwrIstxdFcXhK6d6U0hvLsvxDfU/GX3ij2w2UZXljWZY3pZTW\n1fsswKsriuKClNLGlNJd9T4LECvLcl5Zltv/8l///NfEOh6JlzHoAnQiRVEMSin9c0rpY/U+C/Dq\niqK4uiiKbSmlZ1NKK1JKv6rzkfgrBl2AzuXKlNL3y7J8qd4HAV5dWZYfTCkNTCm9NqV0Y0ppe/Ud\ndCSDLkAnURTFtJTS61NK36j3WYC2K8uypSzL36eUxqaU/r7e5+F/9Kr3AQD4f2allA5KKS0riiKl\nlBpSSj2LojiyLMvX1PFcQNv0Sv4d3U7FG91uoCiKXkVR9Esp9Ux/+tDsVxSFf8iBzue76U8fktP+\n/Ne/p5RuS3/amAJ0IkVR/E1RFBcURdFQFEXPoijOTCm9K/kh0k7FoNs9fDal1JRS+nRK6d1//s+f\nreuJgFcoy3JbWZYr//JXSmlLSqm5LMs19T4b8Apl+tO/pvBSSmlDSulfUkofKcvylrqeiv/FHl0A\nALLkjS4AAFky6AIAkCWDLgAAWTLoAgCQpQ5dMVUUhZ98o1sry7Ko9xnayvNKd9dVnlfPKt1d1bPq\njS4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZMugCAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQJYMu\nAABZMugCAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZMugCAJAlgy4AAFky6AIAkKVe9T4A\nQA4aGhrCNm7cuLDNnz9/XxwH6CBFUYTtyCOPDNt3vvOdsB1zzDFhe8c73hG23/3ud2Frbm4OW868\n0QUAIEsGXQAAsmTQBQAgSwZdAACyZNAFACBLBl0AALJkvVg3MnLkyLCdf/75YZs6dWrYfvGLX4St\nas3J1q1bwwad1cEHHxy2T3ziE2GbN29e2J599tma18uybPvB6mjatGlh+8IXvhC297znPWFrbGzc\nozNBew0ZMiRsJ598cs3rn/rUp8J7Zs6c2a5zbN++PWyf+9znwjZ69OiwXX/99WHbtWtX2w7WBXmj\nCwBAlgy6AABkyaALAECWDLoAAGTJoAsAQJZsXehGdu7cGbaiKMJ2wQUXhK1Hj/iflf7whz+EzdYF\nOquGhoawffCDHwzbW97ylrBde+21YesK2xX69u0btne+851hmzVrVtimT58etnvvvbctx4J2eeMb\n3xi2z3zmM2GLNhAtXbo0vOfBBx8MW9UmpIkTJ4btyCOPbFdrbW0NW8680QUAIEsGXQAAsmTQBQAg\nSwZdAACyZNAFACBLBl0AALJkvVg3snnz5rA99dRTYVu7dm3YBg4cGLampqa2HQw6WNVavJkzZ4at\napXWLbfcErb58+e37WCd1JgxY8JWtUJs+fLlYWtubt6TI0G7RWvCUkpp0aJFYbvppptqXr/zzjvD\ne7Zv3x62iy++OGz/8A//ELYqvXrFY13Pnj3DlvPqMW90AQDIkkEXAIAsGXQBAMiSQRcAgCwZdAEA\nyJJBFwCALFkv1o0URRG2/v37h61qTdiWLVvC1tjY2LaDQQcbP3582D7/+c+HbdOmTWH7/ve/H7aq\n1X6dRdX3hyOOOCJsxx9/fNjuu+++sM2ePbttB4O97Fvf+lbYqlYPRp+Fu3btCu+ZOHFi2A499NCw\nVT2PjzzySNj+67/+K2w7d+4MW8680QUAIEsGXQAAsmTQBQAgSwZdAACyZNAFACBLBl0AALJkvVg3\n0tDQELYpU6aEbdCgQWGrWiFWlmXbDgb7QK9e8be3s846K2yTJ08O27/8y7+E7dFHH23bwTqp3r17\nh+0rX/lKu37N733ve2FrbW1t168Je2rr1q179dcbPXp02D784Q+H7ZRTTgnbqlWrwnbDDTeEbc6c\nOWHrrrzRBQAgSwZdAACyZNAFACBLBl0AALJk0AUAIEsGXQAAsmS9WDcydOjQsB100EFh69Ej/ueh\nzZs378mRYJ857LDDwvb5z38+bM8++2zYfvjDH+7RmTqzo48+OmxVqwnXrVsXtscee2yPzgTtVfVn\ndty4cWF7y1veErYzzzyz5vWpU6eG9/Tr1y9sffr0CVvV+d/whjeE7ZFHHgnb008/HbaceaMLAECW\nDLoAAGTJoAsAQJYMugAAZMmgCwBAlgy6AABkyXqxbuQ1r3lN2KZPnx62HTt2hK2xsXGPzgR7omfP\nnmG76KKLwta3b9+wfeMb3wjb0qVLw1YURbtaa2tr2Pa2qt/3e9/73rCNGTMmbD/4wQ/CtnHjxrYd\nDNrhxBNPDNvFF18cthkzZoStai3h1q1ba15/4oknwnuWLVsWtlmzZoVt7NixYatagdbc3By2K6+8\nMmzPPfdc2Lo6b3QBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkkEXAIAsWS/WjQwePDhsAwYMCNu2\nbdvCtm7duj06E+yJqrV473vf+8J25513hu3GG28MW9XKn4MPPjhs+++/f9heeumlmtfXrFnTrnM0\nNTWFrWq92DHHHBO25cuXh+32228P26pVq8IGbdGjR/w+7owzzgjbO9/5zrBt2LAhbL/4xS/Cdt99\n99W8fuutt4b3rFixImxV674uu+yysA0fPjxs/fv3D1u/fv3CljNvdAEAyJJBFwCALBl0AQDIkkEX\nAIAsGXQBAMiSQRcAgCxZL9aNVK0Qq1o78sQTT7Srwd7Qs2fPsL33ve8N26BBg8J29NFHh+0nP/lJ\n2I4//viw9eoVfzttbW0NW/QMrV+/Prxn4sSJYav632vLli1hq/rf5Le//W3Y7r777rDBvvTzn/88\nbIsWLQpb1VrM2bNnh63qmWyPz3zmM2GbMmVK2E4//fSwzZw5M2wnnnhi2ObPnx+2HTt2hK0r8EYX\nAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkvVi3cjYsWPD1tDQELYVK1aEbe3atXt0Jng1\nRx11VNjOP//8sFWt2Tr00EPDVrW6a9myZWF75plnwtbS0hK2p556qub1qpVkc+fODduYMWPCdskl\nl4Rt1apVYfvEJz4Rtk2bNoWNrqtPnz5hO/bYY2teP+WUU8J7brzxxrA999xzYat6DqpWYlW1rqBq\npVdZlmEbPnx42CZNmhS2UaNGha3q+15X4I0uAABZMugCAJAlgy4AAFky6AIAkCWDLgAAWbJ1oRuZ\nOXNm2AYPHhy2qp+qrvrJUNgd0ZaEgw8+eLfvSSmll156KWy33npr2ObMmRO2m2++OWzr1q0LW9VW\nk8bGxprX+/XrF97Tv3//sF1xxRVhGzBgQNiefPLJsL3wwgtho+vq27dv2C677LKwffGLX6x5/Uc/\n+lF4T9VmBV5pypQpYavaiFG1peKJJ54I2/Lly9t2sC7IG10AALJk0AUAIEsGXQAAsmTQBQAgSwZd\nAACyZNAFACBL1otlKFo9NHbs2Hb9ekuWLAnb1q1b2/VrwsuVZVnzetXaq/e9731he/7558NW9Wd6\ny5YtYWvvOr3Nmzfv9j1NTU1hmzBhQtjOOeecsEWrzFJK6atf/WrYor83dG2TJ08O26c+9amwDRs2\nrOb1nFdUtVdRFGEbP3582KpWEvboEb+jXL9+fdjWrl0btpyfcW90AQDIkkEXAIAsGXQBAMiSQRcA\ngCwZdAEAyJJBFwCALFkvlqHBgwfXvB6tHUsppebm5rDNmTMnbNaLsbe0trbWvL5w4cLwnqo1YS0t\nLXt8pnqqWiH0jne8I2xVq8duvvnmsD3xxBNh27VrV9jous4999ywjRkzJmzbt2+vef3AAw8M7xk4\ncGDYqtbedQVVK8RGjRoVtqrneNCgQWGrWnN41VVXhe3RRx8NW1f/flnFG10AALJk0AUAIEsGXQAA\nsmTQBQAgSwZdAACyZNAFACBL1ot1UQ0NDWGbOXNmzetV68W2bNkStqr1TjmvJKHzy/nP34ABA8L2\n2te+NmzRmraUUvrNb34TtnXr1rXtYGRj06ZNYatab9enT5+a108//fTwnqrPkfvvvz9sTz/9dNiq\n1mx1pP333z9sb3/728N26aWXhq1q5eeDDz4Ytttvvz1sVX+/c+aNLgAAWTLoAgCQJYMuAABZMugC\nAJAlgy4AAFky6AIAkCXrxbqoqtVDhx122G7/eo8++mjYGhsbd/vXA/bM0KFD29V69uwZtqoVg1Vr\nychT1ZqqZcuWhW38+PE1rx9yyCHhPV/84hfDtmjRorB99atfDdvPf/7zsLVX1aqw6Pd30kknhfec\nd955YRs4cGDY7rzzzrB94xvfCFvVOrZdu3aFLWfe6AIAkCWDLgAAWTLoAgCQJYMuAABZMugCAJAl\ngy4AAFmyXqyLGjVqVNiOPPLImter1oTNnj17j88E7D1Tp04NW79+/cLW0NAQtpkzZ4bt5ptvDtva\ntWvDRtf1wAMPhO3cc88N2+WXX17z+vnnnx/eM2jQoLBNmzYtbNddd13YrrnmmrCtWrUqbMuXLw/b\n1q1bw7Zjx46a10eMGBHe07t377D953/+Z9iqfm9r1qwJW3ddIVbFG10AALJk0AUAIEsGXQAAsmTQ\nBQAgSwZdAACyZNAFACBL1ot1UePGjQvbIYccUvN6c3NzeM+mTZv2+EzA7ttvv/1qXj/55JPDe0aP\nHh22DRs2hO2FF14I2/r168NGnsqyDNucOXPC9uUvf7nm9SVLloT3HHfccWE7+OCDwzZ27NiwDR06\nNGyDBw8OW/QZmVL16q4HH3yw5vW77747vOeee+4J20MPPRS2qr83ra2tYeOVvNEFACBLBl0AALJk\n0AUAIEsGXQAAsmTQBQAgSwZdAACyZL1YFzVkyJCwDRgwoOb17du3h/ds3bp1j88E7L5otdK0adPC\ne6KVZCml9Mgjj4TtV7/6VdisLOKvVa23WrhwYc3rV1555b46Tk1Va8mOPvrosE2ePDlsLS0tYbvx\nxhtrXl+wYEF4D/XnjS4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZMugCAJAl68W6qIaGhrD16dOn\n5vXm5ubwni1btuzxmYDdN3369JrXx40bF97T2NgYtqr1Yo8//njbDwad3OLFi9vVbrrppn1xHDop\nb3QBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkkEXAIAsWS/WRQ0YMCBsvXv3rnl948aN4T3Wi0F9\nLF++fLeup1T9vN5yyy1h27VrV9sPBpABb3QBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkq0LXdTq\n1avDtnLlyprXly1bFt6zatWqPT4TsPvmzp1b8/pnP/vZ8J7W1tawzZ8/f4/PBJALb3QBAMiSQRcA\ngCwZdAEAyJJBFwCALBl0AQDIkkEXAIAsWS/WRf3ud78LW0tLS83rVSvEFixYsMdnAnbfmjVrdus6\nAG3njS4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZMugCAJCloizLjvtiRdFxXww6obIsi3qfoa08\nr3R3XeV59azS3VU9q97oAgCQJYMuAABZMugCAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZ\nMugCAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQpaIsy3qfAQAA9jpvdAEAyJJBFwCALBl0AQDIkkEX\nAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkkEXAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCA\nLBl0AQDIkkEXAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkkEXAIAsGXQBAMiSQRcAgCwZ\ndAEAyJJBFwCALBl0AQDIkkEXAIAsGXQBAMiSQTdzRVFsedlfLUVR/N96nwt4Jc8rdB1FUfQtiuL7\nRVEsLYqisSiKJ4qieEO9z8X/1qveB2DfKsuy4S//uSiKhpTSypTSz+t3IiDieYUupVdK6cWU0ikp\npWUppbNTSj8riuKosixfqOfB+B8G3e7l3JTS6pTS/fU+CPCqPK/QiZVluTWl9E9/denWoiiWpJSm\np5ReqMeZeCX/6kL3cnFK6YdlWZb1Pgjwqjyv0IUURTEypXRYSmlevc/C/yh8D+0eiqI4MKW0OKV0\nSFmWS+p9HiDmeYWupSiK3imlX6eUFpVl+f56n4f/4Y1u93FRSun3PjShS/C8QhdRFEWPlNKPUko7\nUkr/UOfj8DIG3e7jPSml6+p9CKBNPK/QBRRFUaSUvp9SGplSOrcsy511PhIv44fRuoGiKE5KKY1J\nfnobOj3PK3Qp16SUjkgpvb4sy6Z6H4ZX8u/odgNFUfxHSql/WZYX1fssQDXPK3QNf/536V9IKW1P\nKe36q/T+siz/qy6H4hUMugAAZMm/owsAQJYMugAAZMmgCwBAlgy6AABkqUPXixVF4Sff6NbKsizq\nfYa28rzS3XWV57UrPKsTJkwI2/Dhw8M2ZsyYsE2bNq1dv2aVnTvjNbgPP/xwzesPPfRQeM/y5cvD\ntmvXrrCxe6qeVW90AQDIkkEXAIAsGXQBAMiSQRcAgCwZdAEAyFKH/r8A7go/GQr7Ulf5Ke6UPK/Q\nVZ7XrvCsfuQjHwnbeeedF7aDDjoobAMGDAhb3759w1YU7fvb2tjYWPP617/+9fCeH/7wh2FbvXp1\nu87BK9m6AABAt2PQBQAgSwZdAACyZNAFACBLBl0AALJk0AUAIEu96n0AAKDrmzVrVthmzJgRtsMO\nOyxsAwcODFuPHvG7uqpWpWrlanSWqt/3gw8+GDbrxTqGN7oAAGTJoAsAQJYMugAAZMmgCwBAlgy6\nAABkyaALAECWrBcDAPbYfvvtF7aePXuGbcOGDWFramoK24gRI8LW3vViRVGErVev2iPT1KlTw3sm\nTJgQtqrVY+w93ugCAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZsl4MANhjK1euDNvjjz8e\ntjVr1oStb9++YTvggAPC1rt377BVrSWbOHFi2Pr06VPz+qhRo8J7jjrqqLCNHj06bCtWrAgbu8cb\nXQAAsmTQBQAgSwZdAACyZNAFACBLBl0AALJk6wJAHUU/HV71U+PNzc1ha21t3eMzQXs8+eSTYXvx\nxRfD1qtXPIpEmw5Sqt66MHDgwLCdcsopYbvkkkvCNnLkyLBFDjnkkLCNGzcubLYu7D3e6AIAkCWD\nLgAAWTLoAgCQJYMuAABZMugCAJAlgy4AAFmyXgzodnr0iP8Zv2ot0UUXXRS2c845J2wjRowI2/bt\n22tev/LKK8N7fve734Vty5YtYYN9qaWlJWwbN24MW8+ePdv19TZs2NCu+6rWmf3t3/5t2NqzXqxq\nTWDV9yH2Hv8rAwCQJYMuAABZMugCAJAlgy4AAFky6AIAkCWDLgAAWbJerM4GDBgQtkMPPTRsRx99\ndNiGDh1a8/rzzz8f3jN//vyw7dy5M2z9+vULW2NjY9iq1sLs2LEjbNBWVSuEJk+eHLaqNWFvfetb\nw3bAAQeEbc2aNWGLVhZVrTJbvHhx2J577rmwtba2hg32pV27drWrVYlW872aqlVn7fn8aWpqCtuS\nJUvC9uSTT+7212L3eaMLAECWDLoAAGTJoAsAQJYMugAAZMmgCwBAlgy6AABkyXqxDjBw4MCwnX32\n2WF7z3veE7YpU6aEbcyYMTWvL1++PLzn4YcfDlvVSqKpU6eGrX///mF76qmnwnbaaaeF7eabbw7b\nlVdeGbZ58+aFjTwNGTIkbO985zvDdsYZZ4Rt0aJFYbv++uvDVrXyK1p1duGFF4b3HHXUUWH74x//\nGLbNmzeHDXJSFEXYqtaSlWW5219r5cqVYata67lt27bd/lrsPm90AQDIkkEXAIAsGXQBAMiSQRcA\ngCwZdAEAyJJBFwCALFkvtpdUrdKaMWNG2N71rneFrWrNVq9eu/+37oADDgjbueeeG7b2rFtJqXq9\nS7QC7dW8/e1vD1tjY2PYPvaxj+32PXRtVc9W1Qqxxx57LGw33HBD2ObPnx+2NWvWhG3Xrl01r190\n0UXhPdOnTw/bQw89FDbrxeguqj4jqz6vhw4duttfq2pd2fr163f712Pv8kYXAIAsGXQBAMiSQRcA\ngCwZdAEAyJJBFwCALBl0AQDIkvVie0nVuqL3ve99YTv++OPD1p4VYp1Je9eSVenRI/5ns6rVY/fd\nd1/N6z/60Y/2+EzUT9XKvCuuuCJsTzzxRNiq/kw88sgjYYvWhL2aaDVRS0tLeM+gQYPC1rNnz3ad\nA3LSp0+fsE2aNClsU6ZMCVv0jG/atCm8Z926dWGjY3ijCwBAlgy6AABkyaALAECWDLoAAGTJoAsA\nQJYMugAAZKlr76/qYMOHDw/b2LFjw1a15uTRRx8NW7QSK6WUFi9eHLbonGPGjGnXr9e7d++wjR49\nOmzHHHNM2KZNmxa2kSNHhq1qvVjVOrbNmzeHja5r3Lhx7Wr/+q//GrZ9sUKsSvTnturPetUz2bdv\n37BV/Zqtra1hg86oKIqwHXzwwWG77LLL2vX1mpuba15/+OGHw3tuv/32dn0t9h5vdAEAyJJBFwCA\nLBl0AQDIkkEXAIAsGXQBAMiSQRcAgCxZL7YbGhsbw3bbbbeF7fHHHw/b9u3bw7Zo0aKwbdiwIWzR\nOrNBgwaF96xduzZsVfr37x+2SZMmhe0f//EfwzZx4sSw3XHHHWHbunVr2O66666w0XVVrfwryzJs\nL774Ytj2xQqxKoceemjN6wMGDAjvmTJlSthOOOGEsK1ZsyZs69evDxt0RlXPeNX3hkMOOSRsVSvL\nmpqaal6/9957w3uoP290AQDIkkEXAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCALFkvthuqVoEtWbIk\nbEuXLm3X12ttbW3XfTt27Kh5vb0rxHr1iv+YjB49OmwzZ84M2+TJk8PWr1+/sN10001he+aZZ8LW\n3NwcNrquIUOGhK1q3Vxn+vMQ/Xnv0SN+DzFt2rSwHXnkkWG7++67w2a9GF3N/vvvH7aTTz45bNEK\nzpSqV5YtWLCg5vU//OEP4T1dRe/evcM2Y8aMsEV/D+6///7wnnXr1rX9YH+lanViFW90AQDIkkEX\nAIAsGXQBAMiSQRcAgCwZdAEAyJKtCx2gvdsTOlLVT1wec8wxYXv/+98ftje84Q3t+nq//vWvw1b1\nk+Gd6Sfp6RgtLS3talWbPfaFqq+3c+fOmterzl9l+fLlYfOMkJOq7T1nnXVW2Kq2LlRtULrllltq\nXl+1alV4T1cxfvz4sH384x8PW7R56Utf+lJ4T9X2pCof+MAH2nWfN7oAAGTJoAsAQJYMugAAZMmg\nCwBAlgy6AABkyaALAECWrBcjpVS97mvq1KlhO++888LW0NAQtqoVYp/73OfC9uKLL4aN7qdqBVdZ\nlmGr+rO5L0yYMCFsJ5xwQs3rQ4cODe9ZtGhR2GbPnh22TZs2hQ26mgsvvDBsRxxxRNiqPu8ee+yx\nsEVrsaq+17RX1Qq0iRMnhu3II48M2ymnnBK26dOnh61qxWiPHrXfl1bNBu1dL3bOOee06z5vdAEA\nyJJBFwCALBl0AQDIkkEXAIAsGXQBAMiSQRcAgCxZL9aN9O3bN2yzZs0K28UXXxy2qjUtt912W9g+\n9rGPhe2ll14KW2tra9jofp5++umw3XzzzWF7/vnn98VxQkcdddRut4EDB4b3VP3eVqxYEbadO3eG\nDTqjM888M2yHH3542Pr169eurzdv3rywNTc317w+fvz48J5x48aFbf/99w/bsGHDwjZ58uSwVX2v\nqVpLNmLEiLD16hWPikVR1Ly+L1Y4PvPMM2GbOXNm2LzRBQAgSwZdAACyZNAFACBLBl0AALJk0AUA\nIEsGXQAAsmS9WDcyZMiQsH3rW98K26hRo8JWte7jox/9aNgWLVoUNmir+fPnh+3qq68O29y5c/fF\ncUJ9+vQJW7S6J1rbk1JKTU1NYWtpaWn7waATOPLII8NWtV5swoQJYatafbl+/fp23Td9+vSa1088\n8cTwnte+9rVh69+/f7vOUbUKrKq1144dO8L25JNP1rx+99137/VzfO973wub9WIAAHQ7Bl0AALJk\n0AUAIEsGXQAAsmTQBQAgSwZdAACyZL1YF9WjR/zPKNF6kUsvvTS858ADDwzbc889F7Zvf/vbYVu8\neHHYYF/r6BViVRYuXBi2devW1bxetUJsxYoVYataBQT1UvWZddJJJ4Vt1qxZYRs9enTYqtbzVa37\nO+uss8J22mmn1bw+ZsyY8J6qdV/77bdf2MqyDFuVnTt3hm3t2rVhi9aEpVS9xvG2227b7Xva67rr\nrgvbtddeGzZvdAEAyJJBFwCALBl0AQDIkkEXAIAsGXQBAMiSQRcAgCxZL9aJ9ezZM2wHHXRQ2D75\nyU/WvH7GGWeE91StP7r44ovD9swzz4StvetRIDdVq8KidWDLli0L77nnnnvCtn79+rYfDDrIsGHD\nwvaa17wmbJMmTQpb1cqyKg0NDWGbPn16u37N9qg6f0tLS9g2bdoUtpdeeilsDz30UNiqvqdUrRid\nN29ezeu7du0K7+lo3ugCAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZsl6szgYPHhy2mTNn\nhu3Nb35z2N7xjnfUvN63b99fyzZfAAAYrUlEQVR2/Xpz584NW9UKFOBPxo8fH7aBAwfWvF610mf1\n6tVh60xrfeAvqtZbHnfccWHr3bv3vjhOu0QrM7du3Rre09zcHLYFCxaEbcOGDWG79957w7ZixYqw\n3XHHHWHLeS2hN7oAAGTJoAsAQJYMugAAZMmgCwBAlgy6AABkyaALAECWrBers0MOOSRsn/70p8M2\nZcqUsG3atKnm9Z/97GfhPffff3/YrBCDV9evX7+wHXHEEWEbOXJkzeuLFy8O74nWHEFndcABB4St\nav1eURT74jihjRs3hm3NmjU1r8+bNy+8p2qF2DPPPBO2lStXtuvXrDp/Y2Nj2HLmjS4AAFky6AIA\nkCWDLgAAWTLoAgCQJYMuAABZMugCAJAl68U6QO/evcN26KGHhm3GjBlha2pqCttPf/rTmte//e1v\nh/fs2LEjbMCrq1qD1NDQELZBgwbVvL506dLwnm3btrX9YNAJrFq1KmwLFy4M2+TJk8O2fPnysD36\n6KNhW716ddg2b94ctnXr1tW8/sADD4T3zJ07N2x0DG90AQDIkkEXAIAsGXQBAMiSQRcAgCwZdAEA\nyJJBFwCALFkv1gEmTJgQtlmzZoVt586dYataWfKDH/yg5vWXXnopvAfYM62trWFbv3592DZs2FDz\n+pAhQ8J7evXyrZuu5a677grbgAEDwnbqqaeG7dlnnw1b1cqvtWvXhq1qvdjGjRtrXl+zZk14D/Xn\njS4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZ8qO7e0nVT0ife+65YXvve98btiVLloTtm9/8Ztie\ne+65sAH7RlEUYav6qfKGhobdup5SSn379m37waATWL16ddiuvfbasF1zzTX74DR0J97oAgCQJYMu\nAABZMugCAJAlgy4AAFky6AIAkCWDLgAAWbJebC857rjjwnbaaaeFbc2aNWG78cYbw/bLX/6ybQcD\nOsSOHTvCtnjx4rBF3wMee+yx8J5169a1/WDQCezcubNdDfaUN7oAAGTJoAsAQJYMugAAZMmgCwBA\nlgy6AABkyaALAECWrBfbSxobG8P23HPPhW3IkCFh27p1a9jGjRsXtmiVUWtra3gPsGeqnq/HH388\nbLfcckvN63/84x/De6xjAmgbb3QBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkkEXAIAsFWVZdtwX\nK4qO+2IdbNiwYWE78MADwzZy5MiwTZs2LWzHH3982C688MKa15uamsJ76BhlWRb1PkNb5fy8Qlt0\nlefVs0p3V/WseqMLAECWDLoAAGTJoAsAQJYMugAAZMmgCwBAlgy6AABkqUPXiwEAQEfxRhcAgCwZ\ndAEAyJJBFwCALBl0AQDIkkEXAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkkEXAIAsGXQB\nAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkkEXAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDI\nkkEXAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkkEXAIAsGXS7gaIori+KYkVRFJuLolhQ\nFMV7630mIFYUxQVFUcwvimJrURSLiqJ4bb3PBLySz9fOryjLst5nYB8rimJySmlhWZbbi6I4PKV0\nb0rpjWVZ/qG+JwNeriiK01NK30spvTOlNDulNDqllMqy/GM9zwW8ks/Xzs8b3W6gLMt5ZVlu/8t/\n/fNfE+t4JCD2xZTSP5dl+XBZlq1lWf7RkAudk8/Xzs+g200URXF1URTbUkrPppRWpJR+VecjAS9T\nFEXPlNKxKaURRVEsLIripaIovl0UxX71PhtQm8/Xzs2g202UZfnBlNLAlNJrU0o3ppS2V98B1MHI\nlFLvlNJ56U/P6rSU0jEppc/W81BAzOdr52bQ7UbKsmwpy/L3KaWxKaW/r/d5gFdo+vP//b9lWa4o\ny3JtSulfU0pn1/FMwKvw+dp5GXS7p17Jv0MEnU5ZlhtSSi+lP/17fv/vcp2OA+w+n6+djEE3c0VR\n/M2fVxU1FEXRsyiKM1NK70op3VXvswE1/WdK6UN/fnaHppQ+mlK6tc5nAl7G52vXYL1Y5oqiGJFS\nuiGlNDX96R9slqaU/q0sy/+vrgcDaiqKondK6VsppQtTSs0ppZ+llD5ZlmVzXQ8G/C8+X7sGgy4A\nAFnyry4AAJAlgy4AAFky6AIAkCWDLgAAWerVkV+sKAo/+Ua3VpZlUe8ztJXntb569Yq/PQ8cODBs\nmzZtClu/fv3Ctm3btrYdrBvpKs+rZ5XurupZ9UYXAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCALBl0\nAQDIUoeuFwOgbVpaWsJ2/PHHt6stXLgwbD/+8Y/bdjCALsQbXQAAsmTQBQAgSwZdAACyZNAFACBL\nBl0AALJk0AUAIEvWiwHUUY8etd83jB49OrzntNNOC9vpp58etvvvvz9s1osBOfJGFwCALBl0AQDI\nkkEXAIAsGXQBAMiSQRcAgCwZdAEAyJL1YgB11NraWvP6oYceGt4zadKksDU3N4ftqaeeavvBADLg\njS4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZMugCAJAl68U6wMCBA8M2ePDgsFWtCdq0aVPYdu7c\n2baDAXU3YMCAmtenTJkS3jNo0KCwzZ07N2x33XVX2w8GkAFvdAEAyJJBFwCALBl0AQDIkkEXAIAs\nGXQBAMiSrQu74d3vfnfYjj322LCNGjUqbCNHjgxba2tr2BobG8M2YsSImtcnTpwY3rNq1aqwLVy4\nMGz33Xdfu9rixYvDtmXLlrC1tLSEDbqiN77xjTWvX3DBBe369e6///6wVT130F307t07bOPGjQvb\n0UcfXfP6hAkTwnuGDRsWtuHDh4et6oz//d//HbbHHnssbGvXrg1b1bzR1XmjCwBAlgy6AABkyaAL\nAECWDLoAAGTJoAsAQJYMugAAZKkoy7LjvlhRdNwXq9CjRzzfn3TSSWG79dZbw9arV7ypbd26dWGr\nWqW1efPmsA0cODBs0Xqxnj17hvdUnb/qvu3bt4ft+eefD9uDDz4Ytqq1ZHfddVfYqv637CzKsizq\nfYa26izPaw6q1gh99atfrXn9rW99a3jPz372s7B94QtfCNuaNWvCxit1lee1uz6rAwYMCNvo0aPD\nNm3atLBdcsklYZs5c2bN64MGDQrvaa9du3aFbenSpWH7yle+Eraf/vSnYdu6dWvbDtZJVT2r3ugC\nAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZ6pbrxapUrdLq169f2KKVXiml1L9//7D16dMn\nbM3NzWGr+vsWtQULFoT3VP2+R40aFbZTTjklbG9+85vDdu6554Zt48aNYata/7Zw4cKwdRZdZV1R\nSl3jee1MhgwZErbLLrssbB/4wAdqXm9qagrvufrqq8P27//+72Fj93SV57WrP6u9e/cO28SJE8N2\n3nnnhe2cc84J24QJE8I2dOjQsBVF5/jjUPX5v3z58rBF69FSSmnZsmV7dKZ6s14MAIBux6ALAECW\nDLoAAGTJoAsAQJYMugAAZMmgCwBAlnrV+wCdTUtLS9i2bt3artYVVP2+V65cGbYnn3wybG9605vC\n1qtX/Edvx44dYVu9enXYoJ6mTJkSthNOOCFsPXrUft/w61//OrzHCjG6mqoVYlVrKr/2ta+FberU\nqWFr7+fI7Nmzw/bAAw/UvF61mqtqTWDVmrOq33fVmrOqVadVfw9y5o0uAABZMugCAJAlgy4AAFky\n6AIAkCWDLgAAWTLoAgCQJevFupGePXuGrWrd1/Tp08P2ne98J2zjxo0L2zPPPBO2q666KmybN28O\nG+xrBx54YNhOPfXUsB1++OFhi9YZffOb32z7waATiFblpZTSpEmTwnbFFVeErWpt3+LFi8N25513\nhu3ee+8N29y5c8O2dOnSmterVpn169cvbCeffHLY2mvjxo17/dfs6rzRBQAgSwZdAACyZNAFACBL\nBl0AALJk0AUAIEsGXQAAsmS9WIb233//mtePOeaY8J5LL700bG95y1vC1tzcHLbf/OY3Yfvud78b\ntvvvvz9ssK/1798/bDNmzAjbWWedFbZt27aF7dprr615fcWKFeE9UE9FUdS8XrVG78tf/nLYzjzz\nzLDNmTMnbF/60pfC9uijj4Zt7dq1YWtpaQlbZL/99gvbzJkzw/bP//zPu/21UkqpLMuwXX311WFb\nv359u75eV+eNLgAAWTLoAgCQJYMuAABZMugCAJAlgy4AAFky6AIAkCXrxTqxYcOGhW369Olhe9vb\n3lbzetWasMGDB4dtyZIlYfv+978ftl/84hdhe/HFF8NWtToF9oYePeJ/xj/00EPD9vrXv75d911/\n/fVhe+CBB8IGndGAAQNqXq9aU3n22WeHbfXq1WG75pprwnbbbbeFrSM/RwYNGhS2WbNmhe24444L\nW9X5t2zZErbHHnssbFXrQHPmjS4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZMugCAJAl68U6QLSK\nJaWUzjnnnLB95CMfCdvw4cPDdtBBB9W8XrWu5Pbbbw/bl770pbDNmTMnbFWrTKwQo56GDBkStpNO\nOilsb3zjG8O2aNGisP3kJz8J2/bt28PWHkVRhK1///5hGzp0aNiq1rEtW7asbQcjG9FnWtWKvao/\nlwsWLAjb3Llzw9bRnyPRM1K1Ou3tb3972KrOv379+rB95StfCdujjz4atr39vaar8EYXAIAsGXQB\nAMiSQRcAgCwZdAEAyJJBFwCALBl0AQDIkvViHeCII44I24c+9KGwHXvssWGrWtUS2bVrV9iqVoEN\nGzYsbC0tLWGzQox6qlqJNW7cuLC9613vClvfvn3D9uMf/zhszz//fNh27twZtvYYP3582GbMmBG2\nadOmha1Xr/ij4u677w7bPffcE7ampqaw0blFnyVVa8KefPLJsN1xxx1hW7duXdsPthfsv//+YTv/\n/PNrXv/oRz8a3nPIIYeEbcuWLWG78cYbw3bdddeFbcOGDWHrrp/J3ugCAJAlgy4AAFky6AIAkCWD\nLgAAWTLoAgCQpaIjfwqvKIru+SN/FQ444ICwHXbYYWGr+snQo446qub1E088Mbxn0qRJYavyH//x\nH2H76U9/GrYXX3wxbFWbHLq6six3f11GnXT157VqM8nnP//5sH34wx8O269+9auwff3rXw/bM888\nE7boJ9iHDBkS3nPaaaeF7aKLLgrbSSedFLbhw4eHrWpjyxNPPBG2d7/73WGr+gn9zqKrPK8d/axG\nWzgOPvjg8J6qz6wXXnghbFVbF9q7sWTkyJFhu+CCC8L293//9zWvV/2+q85/3333he2f/umfwjZ/\n/vywdVdVz6o3ugAAZMmgCwBAlgy6AABkyaALAECWDLoAAGTJoAsAQJZq7wihwyxfvjxsK1asCFvV\nWrhf/vKXNa+PGjUqvOe4444L29/93d+F7corrwzb6aefHrbzzjsvbBs3bgwbtNWIESPCNnny5LBV\nrTq69dZbw7Zw4cKwVa3nitYIfvCDHwzv+dCHPhS2zZs3h+3xxx8PW9W6r4aGhrCdffbZYav6HrB1\n69aw/fGPfwwb9Rf9ea76M1S17q8j15ymlNIJJ5wQtmiFWEopHXLIITWvb9iwIbwn+jxOKaV/+7d/\nC9tzzz0XNnaPN7oAAGTJoAsAQJYMugAAZMmgCwBAlgy6AABkyaALAECWrBfrxNq7cmXnzp01r7/4\n4ovhPStXrgxb1RqgY445Jmyvec1rwnbqqaeG7ZZbbglb1Zom+Guve93rwjZgwICw/eY3vwnbQw89\nFLZt27aF7cADDwzbe97znprXL7/88vCel156KWx33HFH2K666qqwPf/882G78MILw3b88ceHbcaM\nGWGrWnVmvVh+OnqFWJWxY8eGbcyYMWGLVqTNnz8/vOe73/1u2J5++umwsfd4owsAQJYMugAAZMmg\nCwBAlgy6AABkyaALAECWDLoAAGTJerHd0LNnz7D16dMnbE1NTfviOHtVtJIspeoVKDfddFPYLrnk\nkrBdeumlYbvxxhvDBm1V9Uzu2LEjbI888kjYli5d2q6z9O/fP2xHHXVUzeuzZ88O77nuuuvCVvVM\njhgxImwf//jHw3b22WeHbfTo0WHbsmVL2DZv3hw22JeqPsujFWJV1q9fH7aqVYB0DG90AQDIkkEX\nAIAsGXQBAMiSQRcAgCwZdAEAyJJBFwCALFkv9jJVa0eOPvrosB1//PFh+8lPfhK2TZs2te1gdbR8\n+fKwVa0eK8sybAcccEDY/uZv/iZsq1evDhv8tcWLF4etoaEhbFWr9qr06hV/O61adTZ16tSa12+9\n9dbwnrlz54bt5JNPDtt5550XtlNPPTVsVWvJ7rnnnrDdcMMNYav63gH7UtVnU9Xz369fv5rXJ02a\nFN5z/vnnh+3OO+8M27PPPhu2qvPzSt7oAgCQJYMuAABZMugCAJAlgy4AAFky6AIAkCWDLgAAWbJe\n7GUGDBgQtne/+91hq1oh0r9//7B985vfDFtnWSFSdY5Vq1aFbenSpWFbv3592AYNGhQ268Voqzlz\n5oRt4cKFYbv88svDNnTo0LA99NBDYRs/fnzYopVFM2fODO85/PDDwzZq1KiwVZ1/7dq1Ybv++uvD\ndt1114XNCjE6o7vvvjtsVasv3/a2t9W8fvDBB4f3fPrTnw5b1VrSL3zhC2FbsmRJ2DrL3NCZeKML\nAECWDLoAAGTJoAsAQJYMugAAZMmgCwBAlgy6AABkyXqxl2lpaQlb1dqr4cOHh+3kk08O26233hq2\n559/PmwdqWo9WtXvreq+J554ImwrV65s28Ggwo4dO8L2ta99LWz/5//8n7BVrfwZMWJE2BoaGsLW\n1NRU83rPnj3De3r37h222bNnh+2GG24I2x133BG2nTt3hg3qZb/99gtb1efP4sWLw/atb30rbD16\n1H43+OEPfzi8p2rd35vf/OawVa3grPoetXXr1rB1V97oAgCQJYMuAABZMugCAJAlgy4AAFky6AIA\nkCWDLgAAWbJe7GWqVnP89re/DdvZZ58dtlmzZoXtjDPOCFvVmq3GxsawFUVR83qfPn3Ce6pWGX3w\ngx8M29ve9rawVa13evDBB8O2ZcuWsMHe8MILL4Ttk5/8ZNimT58etkmTJoWt6vmKnvMlS5bs9j0p\npbRmzZqwbd++PWzQ1Zxwwglhe/3rXx+2W265JWxPPfVU2ObNm1fz+qZNm8J7qtYOVq1He8Mb3hC2\nb3zjG2Frbm4OW9X61Jx5owsAQJYMugAAZMmgCwBAlgy6AABkyaALAECWDLoAAGTJerHdcPvtt4dt\n8eLFYTv22GPDdumll4Zt2LBhYXvkkUfCFq06Ofroo8N7rrjiirCNGjUqbKtXrw7bNddcE7aq80M9\nbdy4MWx33XVXuxrQPv369QvbqaeeGrb3v//9Yatas1W1CjBaIRit9Hw1Vev+Hn744bBt3rw5bK2t\nre06S8680QUAIEsGXQAAsmTQBQAgSwZdAACyZNAFACBLBl0AALJkvdhu2LJlS9guv/zysH3oQx8K\n2ymnnBK2T3ziE2GrWmcStT59+oT3VK0rmT17dtiuuuqqsD300ENha2pqChsApJTSyJEjw3bUUUeF\nraGhIWxnnXVW2F73uteF7fDDD9/tr9Xc3By2aBVoSinNmzcvbNu2bQtbWZZh66680QUAIEsGXQAA\nsmTQBQAgSwZdAACyZNAFACBLti7shtbW1rA9++yzYavaTPDggw+G7eyzzw7bkUceGbbBgwfXvP77\n3/8+vOdXv/pV2ObMmRO2qp8M9dOfAOyJqs+Rqk1CPXrE7/HGjh0btsbGxrAtWLCg5vV169aF92zY\nsCFsP//5z8NW9bm7Y8eOsPFK3ugCAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZKjpyBVRR\nFPZNdYBo5UpDQ0N4z/bt28O2bdu2sFkhtnvKsizqfYa28rzS3XWV5zXnZ7Vv375he9Ob3hS2qvWc\nTz31VLtatF7sxRdfDO/p1Sve4loU8R+vlpaWsFWtOu2uqp5Vb3QBAMiSQRcAgCwZdAEAyJJBFwCA\nLBl0AQDIkkEXAIAsWS8GHairrCtKyfMKXeV59azS3VkvBgBAt2PQBQAgSwZdAACyZNAFACBLBl0A\nALJk0AUAIEsGXQAAsmTQBQAgSwZdAACyZNAFACBLBl0AALJk0AUAIEsGXQAAslSUZVnvMwAAwF7n\njS4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZMugCAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQJYMu\nAABZMugCAJAlgy4AAFky6AIAkCWDLgAAWTLoAgCQJYMuAABZMugCAJAlgy4AAFky6AIAkCWDLgAA\nWTLoAgCQJYMuAABZ+v8B+lNgti5qONkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFoyXg1z9IG0",
        "colab_type": "text"
      },
      "source": [
        "ดู label ตัวเลขทั้งหมด หรือ class ทั้งหมด ที่มีใน Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8JTsQMRp9IG2",
        "colab_type": "code",
        "outputId": "998818eb-49d9-4f8d-a040-5525aba7a1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "databunch.classes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A9U0dSc9IG8",
        "colab_type": "text"
      },
      "source": [
        "# 4. สร้างโมเดล"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWbboIYBKUsh",
        "colab_type": "text"
      },
      "source": [
        "เราจะสร้างโมเดล Deep Convolutional Neural Network ที่มี 4 ConvLayer และใช้ GeneralRelu ดังด้านล่าง"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1596sMU524y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cnn_model(data, **kwargs):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(  3,  8, 5, padding=2, stride=2), GeneralRelu(**kwargs), #14\n",
        "        nn.Conv2d(  8, 16, 3, padding=1, stride=2), GeneralRelu(**kwargs), # 7\n",
        "        nn.Conv2d( 16, 32, 3, padding=1, stride=2), GeneralRelu(**kwargs), # 4\n",
        "        nn.Conv2d( 32, 32, 3, padding=1, stride=2), GeneralRelu(**kwargs), # 2\n",
        "        nn.AdaptiveAvgPool2d(1), \n",
        "        Lambda(flatten), \n",
        "        nn.Linear(32, data.c)\n",
        "    )\n",
        "\n",
        "class GeneralRelu(nn.Module): \n",
        "    def __init__(self, leak=None, sub=None, maxv=None):\n",
        "        super().__init__()\n",
        "        self.leak, self.sub, self.maxv = leak, sub, maxv\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(x, self.leak) if self.leak is not None else F.relu(x)\n",
        "        if self.sub is not None: x.sub_(self.sub)\n",
        "        if self.maxv is not None: x.clamp_max_(self.maxv)\n",
        "        return x\n",
        "\n",
        "# def mnist_resize(x): return x.view(-1, 1, 28, 28)\n",
        "def flatten(x): return x.view(x.shape[0], -1)    \n",
        "\n",
        "def init_cnn(m, uniform=False, bias=True):\n",
        "    f = init.kaiming_uniform_ if uniform else init.kaiming_normal_\n",
        "    for l in m:\n",
        "        if isinstance(l, nn.Conv2d):\n",
        "            f(l.weight, a=0.1)\n",
        "            if bias: l.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayoQr8d8GfGH",
        "colab_type": "text"
      },
      "source": [
        "สร้างโมเดล และ Initialize ด้วย Kaiming Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5GtebtB_uhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_cnn_model(databunch, leak=0.1, sub=0.4, maxv=6.)\n",
        "init_cnn(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1beHqEr_vRv",
        "colab_type": "code",
        "outputId": "d694af3a-c594-402e-fb4c-436e5d17fb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (1): GeneralRelu()\n",
              "  (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (3): GeneralRelu()\n",
              "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (5): GeneralRelu()\n",
              "  (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (7): GeneralRelu()\n",
              "  (8): AdaptiveAvgPool2d(output_size=1)\n",
              "  (9): Lambda()\n",
              "  (10): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa99vDjuKZdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def children(m): list(m.children())\n",
        "\n",
        "class Hook():\n",
        "    # m = module, f = function\n",
        "    def __init__(self, m, f): self.hook = m.register_forward_hook(partial(f, self))\n",
        "    def remove(self): self.hook.remove()\n",
        "    def __del__(self): self.remove()\n",
        "\n",
        "def append_stats(hook, mod, inp, outp):\n",
        "    if not hasattr(hook, 'stats'): hook.stats = ([], [], [])\n",
        "    means, stds, hists = hook.stats \n",
        "    means.append(outp.data.mean().cpu())\n",
        "    stds.append(outp.data.std().cpu())\n",
        "    # Tensor.histc(bins, min, max)\n",
        "    hists.append(outp.data.cpu().histc(80, -10, 10))\n",
        "\n",
        "class ListContainer():\n",
        "    def __init__(self, items): self.items = listify(items)\n",
        "    def __getitem__(self, idx): \n",
        "        if isinstance(idx, (int, slice)): return self.items[idx]\n",
        "        if isinstance(idx[0], bool):\n",
        "            assert len(idx) == len(self) # boolean mask\n",
        "            return [o for m, o in zip(idx, self.items) if m]\n",
        "        return [self.items[i] for i in idx]\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __iter__(self): return iter(self.items)\n",
        "    def __setitem__(self, i, o): self.items[i] = o\n",
        "    def __delitem__(self, i): del(self.items[i])\n",
        "    def __repr__(self):\n",
        "        res = f'{self.__class__.__name__} ({len(self)} items)\\n{self.items[:10]}'\n",
        "        if len(self) > 10: res = res[:-1] + '...]'\n",
        "        return res\n",
        "        \n",
        "class Hooks(ListContainer):\n",
        "    def __init__(self, ms, f): super().__init__([Hook(m, f) for m in ms])\n",
        "    def __enter__(self, *args): return self\n",
        "    def __exit__(self, *args): self.remove()\n",
        "    def __del__(self): self.remove()\n",
        "\n",
        "    def __delitem__(self, i):\n",
        "        self[i].remove()\n",
        "        super().__delitem__(i)\n",
        "    \n",
        "    def remove(self):\n",
        "        for h in self: h.remove()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4IxTVh39IG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = Learner(databunch, model, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjm7EsmT9IHD",
        "colab_type": "text"
      },
      "source": [
        "# 5. เริ่มต้นเทรนโมเดล\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcbpWiI_GsfR",
        "colab_type": "text"
      },
      "source": [
        "พล็อตกราฟ Mean และ Variant ของ 10 Iteration แรก และ กราฟ Mean และ Variant ของตลอดการเทรน"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlZCwwUd3Hgf",
        "colab_type": "code",
        "outputId": "aa791a2b-d92d-458c-fe7a-28820b2a46a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        }
      },
      "source": [
        "with Hooks(learner.model, append_stats) as hooks: \n",
        "\n",
        "    learner.fit_one_cycle(1, max_lr=max_lr, wd=wd)\n",
        "\n",
        "    # Plot first 10 iterations.\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    for h in hooks[[0, 2, 4, 6]]:\n",
        "        # ms = means, ss = stds, _ = histogram\n",
        "        ms, ss, _ = h.stats\n",
        "        ax0.plot(ms[:10])\n",
        "        ax1.plot(ss[:10])\n",
        "        h.remove()\n",
        "    plt.legend(range(4))\n",
        "\n",
        "    # Plot all\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    for h in hooks[[0, 2, 4, 6]]:\n",
        "        ms, ss, _ = h.stats\n",
        "        ax0.plot(ms)\n",
        "        ax1.plot(ss)\n",
        "    plt.legend(range(4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='191' class='' max='875', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      21.83% [191/875 00:20<01:14 0.5385]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0R_zP8BxZqb",
        "colab_type": "text"
      },
      "source": [
        "# 6. Intepret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfqr70ZYG634",
        "colab_type": "text"
      },
      "source": [
        "ดู Histogram ของ Activation Map ว่าอยู่ไหนช่วงไหนกันบ้าง ทั้งแต่ -10 ถึง 10 ตรงกลางคือ 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3PTzCo_I8pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_hist(h): return torch.stack(h.stats[2]).t().float().log1p()[:,:200]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
        "for ax, h in zip(axes.flatten(), hooks[[0, 2, 4, 6]]):\n",
        "    ax.imshow(get_hist(h), origin='lower')\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St8R0NUEHJp7",
        "colab_type": "text"
      },
      "source": [
        "พล็อตกราฟสัดส่วนของ Activation Map ที่มีค่าน้อย ต่อ Activation Map ทั้งหมด"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1CLJ77sTiVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_min(h):\n",
        "    # stats = mean, std, histogram, stats[2] = hists\n",
        "    h1 = torch.stack(h.stats[2]).t().float()\n",
        "    return h1[38:42].sum(0)/h1.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHw8bK43TjUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
        "for ax, h in zip(axes.flatten(), hooks[[0, 2, 4, 6]]):\n",
        "    ax.plot(get_min(h))\n",
        "    ax.set_ylim(0, 1)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujgJypAb2w4u",
        "colab_type": "text"
      },
      "source": [
        "# 4/2. Model with BatchNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-W0eDJXHh5B",
        "colab_type": "text"
      },
      "source": [
        "ประกาศ BatchNorm Layer สำหรับใช้ในโมเดลใหม่"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKzAMa5umqEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNorm(nn.Module):\n",
        "    def __init__(self, nf, mom=0.1, eps=1e-5): \n",
        "        super().__init__()\n",
        "        # mom is 1 - momentum\n",
        "        self.mom, self.eps = mom, eps\n",
        "        self.mults = nn.Parameter(torch.ones(nf, 1, 1))\n",
        "        self.adds = nn.Parameter(torch.zeros(nf, 1, 1))\n",
        "        self.register_buffer('vars', torch.ones(1, nf, 1, 1))\n",
        "        self.register_buffer('means', torch.zeros(1, nf, 1, 1))\n",
        "\n",
        "    def update_status(self, x):\n",
        "        # find mean, var by batch, widht, height for each channel but keep dimension\n",
        "        m = x.mean((0, 2, 3), keepdim=True)\n",
        "        v = x.var((0, 2, 3), keepdim=True)\n",
        "        self.means.lerp_(m, self.mom)\n",
        "        self.vars.lerp_(v, self.mom)\n",
        "        return m, v\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training: \n",
        "            with torch.no_grad(): m, v = self.update_status(x)\n",
        "        else: m, v = self.means, self.vars\n",
        "        x = (x - m) / (v + self.eps).sqrt()\n",
        "        return (x * self.mults) + self.adds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH6wIerAHTfI",
        "colab_type": "text"
      },
      "source": [
        "สร้างโมเดลใหม่ ที่มี BatchNorm แทรกอยู่หลัง Activation Function ในที่นี้คือ GeneralReLU แต่ ConvLayer ไม่จำเป็นต้องมี Bias แล้ว เพราะมีใน BatchNorm ให้แล้ว"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZVAXhmory3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cnn_model(data, **kwargs):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(  3,  8, 5, padding=2, stride=2, bias=False), GeneralRelu(**kwargs), BatchNorm( 8), #14\n",
        "        nn.Conv2d(  8, 16, 3, padding=1, stride=2, bias=False), GeneralRelu(**kwargs), BatchNorm(16), # 7\n",
        "        nn.Conv2d( 16, 32, 3, padding=1, stride=2, bias=False), GeneralRelu(**kwargs), BatchNorm(32), # 4\n",
        "        nn.Conv2d( 32, 32, 3, padding=1, stride=2, bias=False), GeneralRelu(**kwargs), BatchNorm(32), # 2\n",
        "        nn.AdaptiveAvgPool2d(1), \n",
        "        Lambda(flatten), \n",
        "        nn.Linear(32, data.c)\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG7H4Mh6H3pI",
        "colab_type": "text"
      },
      "source": [
        "Initialize โมเดลด้วย Kaiming Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHYXH1HxtqtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_cnn_model(databunch, leak=0.1, sub=0.4, maxv=6.)\n",
        "init_cnn(model, bias=False)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfWkWlXptq4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = Learner(databunch, model, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRWda7tmtq-P",
        "colab_type": "text"
      },
      "source": [
        "# 5/2. Train with BatchNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQLv1qnDIM0P",
        "colab_type": "text"
      },
      "source": [
        "เทรน 1 Epoch เหมือนด้านบน เพื่อเปรียบเทียบ แต่เราสามารถเพิ่ม Maximum Learning Rate เป็น 2 เท่า ทำให้เทรนได้เร็วขึ้นอีก\n",
        "\n",
        "และเราจะพล็อตกราฟ Mean, Std จาก ConvLayer คือ Layer ที่ 0, 3, 6, 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBadwEcEtrEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with Hooks(learner.model, append_stats) as hooks: \n",
        "\n",
        "    learner.fit_one_cycle(1, max_lr=max_lr*2, wd=wd)\n",
        "\n",
        "    # Plot first 10 iterations.\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    for h in hooks[[0, 3, 6, 9]]:       # ConvLayer\n",
        "    # for h in hooks[[2, 5, 8, 11]]:    # BatchNorm Layer\n",
        "\n",
        "        # ms = means, ss = stds, _ = histogram\n",
        "        ms, ss, _ = h.stats\n",
        "        ax0.plot(ms[:10])\n",
        "        ax1.plot(ss[:10])\n",
        "        h.remove()\n",
        "    plt.legend(range(4))\n",
        "\n",
        "    # Plot all\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    for h in hooks[[0, 3, 6, 9]]:       # ConvLayer\n",
        "    # for h in hooks[[2, 5, 8, 11]]:    # BatchNorm Layer\n",
        "        ms, ss, _ = h.stats\n",
        "        ax0.plot(ms)\n",
        "        ax1.plot(ss)\n",
        "    plt.legend(range(4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyBpUXJixhLh",
        "colab_type": "text"
      },
      "source": [
        "# 6/2. Intepret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI7oWVsZISWV",
        "colab_type": "text"
      },
      "source": [
        "เราจะพล็อตกราฟ Histogram ของ Activation Map ของ Layer ที่ 0, 3, 6, 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_rZIBXlt-t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
        "for ax, h in zip(axes.flatten(), hooks[[0, 3, 6, 9]]):    # ConvLayer\n",
        "# for ax, h in zip(axes.flatten(), hooks[[2, 5, 8, 11]]):     # BatchNorm Layer\n",
        "    ax.imshow(get_hist(h), origin='lower')\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PM03CZ1Isth",
        "colab_type": "text"
      },
      "source": [
        "เราจะพล็อตกราฟ สัดส่วน Activation Map ของ Layer ที่ 0, 3, 6, 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJd3WOftudMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
        "for ax, h in zip(axes.flatten(), hooks[[0, 3, 6, 9]]):    # ConvLayer\n",
        "# for ax, h in zip(axes.flatten(), hooks[[2, 5, 8, 11]]):     # BatchNorm Layer\n",
        "    ax.plot(get_min(h))\n",
        "    ax.set_ylim(0, 1)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p228QDar6C8F"
      },
      "source": [
        "# 4/3. Model with BatchNorm (Small Batch Size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W75v7WXJ7zxQ",
        "colab_type": "text"
      },
      "source": [
        "BatchNorm จะมีปัญหากับ Batch Size ที่เล็ก เพราะ Mean, Std ค่อนข้างเหวี่ยงเกินไป เราจะลองเทรนด้วย Batch Size น้อย ๆ เช่น 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SxJ9EZc6Z6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsize = 4\n",
        "databunch = ImageDataBunch.from_folder(path, train='training', valid_pct=0.2, size=28, \n",
        "                                       ds_tfms=transform, bs=batchsize, num_workers=8).normalize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_1tilk_e6C8T",
        "colab": {}
      },
      "source": [
        "model = get_cnn_model(databunch, leak=0.1, sub=0.4, maxv=6.)\n",
        "init_cnn(model, bias=False)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pqhNMrrC6C8W",
        "colab": {}
      },
      "source": [
        "learner = Learner(databunch, model, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_EFhae5Y6C8Y"
      },
      "source": [
        "# 5/3. Train (Small Bath Size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eaLtZBbh6C8Y"
      },
      "source": [
        "เทรน 1 Epoch เหมือนด้านบน เพื่อเปรียบเทียบ แต่เราสามารถเพิ่ม Maximum Learning Rate เป็น 2 เท่า ทำให้เทรนได้เร็วขึ้นอีก\n",
        "\n",
        "และเราจะพล็อตกราฟ Mean, Std จาก ConvLayer คือ Layer ที่ 0, 3, 6, 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F6Mc_HWZ6C8Z",
        "colab": {}
      },
      "source": [
        "with Hooks(learner.model, append_stats) as hooks: \n",
        "\n",
        "    learner.fit_one_cycle(1, max_lr=max_lr*2, wd=wd)\n",
        "\n",
        "    # Plot first 10 iterations.\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    for h in hooks[[0, 3, 6, 9]]:       # ConvLayer\n",
        "    # for h in hooks[[2, 5, 8, 11]]:    # BatchNorm Layer\n",
        "\n",
        "        # ms = means, ss = stds, _ = histogram\n",
        "        ms, ss, _ = h.stats\n",
        "        ax0.plot(ms[:10])\n",
        "        ax1.plot(ss[:10])\n",
        "        h.remove()\n",
        "    plt.legend(range(4))\n",
        "\n",
        "    # Plot all\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    for h in hooks[[0, 3, 6, 9]]:       # ConvLayer\n",
        "    # for h in hooks[[2, 5, 8, 11]]:    # BatchNorm Layer\n",
        "        ms, ss, _ = h.stats\n",
        "        ax0.plot(ms)\n",
        "        ax1.plot(ss)\n",
        "    plt.legend(range(4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nIvnqKWm6C8c"
      },
      "source": [
        "# 6/3. Intepret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Aw0D-jW6C8c"
      },
      "source": [
        "เราจะพล็อตกราฟ Histogram ของ Activation Map ของ Layer ที่ 0, 3, 6, 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AIGjLGUv6C8d",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
        "for ax, h in zip(axes.flatten(), hooks[[0, 3, 6, 9]]):    # ConvLayer\n",
        "# for ax, h in zip(axes.flatten(), hooks[[2, 5, 8, 11]]):     # BatchNorm Layer\n",
        "    ax.imshow(get_hist(h), origin='lower')\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r26wSQxd6C8f"
      },
      "source": [
        "เราจะพล็อตกราฟ สัดส่วน Activation Map ของ Layer ที่ 0, 3, 6, 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1J-M4lAC6C8g",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
        "for ax, h in zip(axes.flatten(), hooks[[0, 3, 6, 9]]):    # ConvLayer\n",
        "# for ax, h in zip(axes.flatten(), hooks[[2, 5, 8, 11]]):     # BatchNorm Layer\n",
        "    ax.plot(get_min(h))\n",
        "    ax.set_ylim(0, 1)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TmPTjyFw9tgb"
      },
      "source": [
        "# 4/4. Running BatchNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UFea4H1v9tgn"
      },
      "source": [
        "Running BatchNorm ที่มาแก้ปัญหา Batch Size เล็ก ด้วยการใช้ Running Mean, Running Variant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FWtx2OEC9tgo",
        "colab": {}
      },
      "source": [
        "class RunningBatchNorm(nn.Module):\n",
        "    def __init__(self, nf, mom=0.1, eps=1e-5): \n",
        "        super().__init__()\n",
        "        self.mom, self.eps = mom, eps\n",
        "        self.mults = nn.Parameter(torch.ones(nf, 1, 1))\n",
        "        self.adds = nn.Parameter(torch.zeros(nf, 1, 1))\n",
        "        self.register_buffer('sums', torch.zeros(1, nf, 1, 1))\n",
        "        self.register_buffer('sqrs', torch.zeros(1, nf, 1, 1))\n",
        "        self.register_buffer('batch', torch.tensor(0.))\n",
        "        self.register_buffer('count', torch.tensor(0.))\n",
        "        self.register_buffer('step', torch.tensor(0.))\n",
        "        self.register_buffer('dbias', torch.tensor(0.))\n",
        "\n",
        "    def update_status(self, x):\n",
        "        # bs = batch size, nc = no of channels\n",
        "        bs, nc, *_ = x.shape\n",
        "        self.sums.detach_()\n",
        "        self.sqrs.detach_()\n",
        "        dims = (0, 2, 3)\n",
        "        # s = sum, ss = sum of squared, c = count\n",
        "        s = x.sum(dims, keepdim=True)\n",
        "        ss = (x*x).sum(dims, keepdim=True)\n",
        "        c = self.count.new_tensor(x.numel()/nc)\n",
        "        mom1 = 1 - (1-self.mom)/math.sqrt(bs-1)\n",
        "        self.mom1 = self.dbias.new_tensor(mom1)\n",
        "        self.sums.lerp_(s, self.mom1)\n",
        "        self.sqrs.lerp_(ss, self.mom1)\n",
        "        self.count.lerp_(c, self.mom1) \n",
        "        self.dbias = self.dbias*(1-self.mom1) + self.mom1\n",
        "        self.batch += bs\n",
        "        self.step += 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:  self.update_status(x)\n",
        "        sums = self.sums\n",
        "        sqrs = self.sqrs\n",
        "        c = self.count\n",
        "        if self.step < 100:\n",
        "            sums = sums / self.dbias\n",
        "            sqrs = sqrs / self.dbias\n",
        "            c = c / self.dbias\n",
        "        means = sums / c\n",
        "        vars = (sqrs/c).sub_(means*means)\n",
        "        if bool(self.batch < 20): vars.clamp_min_(0.01)\n",
        "        x = (x-means).div_((vars.add_(self.eps)).sqrt())\n",
        "        return x.mul_(self.mults).add_(self.adds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Evyarftw9tgt"
      },
      "source": [
        "สร้างโมเดลใหม่ ที่มี BatchNorm แทรกอยู่หลัง Activation Function ในที่นี้คือ GeneralReLU แต่ ConvLayer ไม่จำเป็นต้องมี Bias แล้ว เพราะมีใน BatchNorm ให้แล้ว"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z3Dqa7d09tgv",
        "colab": {}
      },
      "source": [
        "def get_cnn_model(data, **kwargs):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(  3,  8, 5, padding=2, stride=2, bias=False), GeneralRelu(**kwargs), RunningBatchNorm( 8), #14\n",
        "        nn.Conv2d(  8, 16, 3, padding=1, stride=2, bias=False), GeneralRelu(**kwargs), RunningBatchNorm(16), # 7\n",
        "        nn.Conv2d( 16, 32, 3, padding=1, stride=2, bias=False), GeneralRelu(**kwargs), RunningBatchNorm(32), # 4\n",
        "        nn.Conv2d( 32, 32, 3, padding=1, stride=2, bias=False), GeneralRelu(**kwargs), RunningBatchNorm(32), # 2\n",
        "        nn.AdaptiveAvgPool2d(1), \n",
        "        Lambda(flatten), \n",
        "        nn.Linear(32, data.c)\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZielLWFn9tgy"
      },
      "source": [
        "Initialize โมเดลด้วย Kaiming Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj0WortfCAM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsize = 4\n",
        "databunch = ImageDataBunch.from_folder(path, train='training', valid_pct=0.2, size=28, \n",
        "                                       ds_tfms=transform, bs=batchsize, num_workers=8).normalize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2MCB4H529tg1",
        "colab": {}
      },
      "source": [
        "model = get_cnn_model(databunch, leak=0.1, sub=0.4, maxv=6.)\n",
        "init_cnn(model, bias=False)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TrQ1M0IN9tg5",
        "colab": {}
      },
      "source": [
        "learner = Learner(databunch, model, metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6kV3_mG69tg8"
      },
      "source": [
        "# 5/4. Train Small Batch Size with RunningBatchNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wgt5tTWG9tg9"
      },
      "source": [
        "เทรน 1 Epoch เหมือนด้านบน เพื่อเปรียบเทียบ แต่เราสามารถเพิ่ม Maximum Learning Rate เป็น 2 เท่า ทำให้เทรนได้เร็วขึ้นอีก\n",
        "\n",
        "และเราจะพล็อตกราฟ Mean, Std จาก ConvLayer คือ Layer ที่ 0, 3, 6, 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4u8GqhiK9tg-",
        "colab": {}
      },
      "source": [
        "with Hooks(learner.model, append_stats) as hooks: \n",
        "\n",
        "    learner.fit_one_cycle(1, max_lr=max_lr*2, wd=wd)\n",
        "\n",
        "    # Plot first 10 iterations.\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    for h in hooks[[0, 3, 6, 9]]:       # ConvLayer\n",
        "    # for h in hooks[[2, 5, 8, 11]]:    # BatchNorm Layer\n",
        "\n",
        "        # ms = means, ss = stds, _ = histogram\n",
        "        ms, ss, _ = h.stats\n",
        "        ax0.plot(ms[:10])\n",
        "        ax1.plot(ss[:10])\n",
        "        h.remove()\n",
        "    plt.legend(range(4))\n",
        "\n",
        "    # Plot all\n",
        "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    for h in hooks[[0, 3, 6, 9]]:       # ConvLayer\n",
        "    # for h in hooks[[2, 5, 8, 11]]:    # BatchNorm Layer\n",
        "        ms, ss, _ = h.stats\n",
        "        ax0.plot(ms)\n",
        "        ax1.plot(ss)\n",
        "    plt.legend(range(4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SGhxFcpb9thD"
      },
      "source": [
        "# 6/4. Intepret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u8P9R_iQ9thE"
      },
      "source": [
        "เราจะพล็อตกราฟ Histogram ของ Activation Map ของ Layer ที่ 0, 3, 6, 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "76BhDqfb9thF",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
        "for ax, h in zip(axes.flatten(), hooks[[0, 3, 6, 9]]):    # ConvLayer\n",
        "# for ax, h in zip(axes.flatten(), hooks[[2, 5, 8, 11]]):     # BatchNorm Layer\n",
        "    ax.imshow(get_hist(h), origin='lower')\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4fnE0a1U9thI"
      },
      "source": [
        "เราจะพล็อตกราฟ สัดส่วน Activation Map ของ Layer ที่ 0, 3, 6, 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EJDcTrfb9thJ",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
        "for ax, h in zip(axes.flatten(), hooks[[0, 3, 6, 9]]):    # ConvLayer\n",
        "# for ax, h in zip(axes.flatten(), hooks[[2, 5, 8, 11]]):     # BatchNorm Layer\n",
        "    ax.plot(get_min(h))\n",
        "    ax.set_ylim(0, 1)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLb4hoHmvWqx",
        "colab_type": "text"
      },
      "source": [
        "# 7. สรุป"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR528lzsvXLP",
        "colab_type": "text"
      },
      "source": [
        "เปรียบเทียบ [ConvNet](https://www.bualabs.com/archives/2461/what-is-convolutional-neural-network-cnn-convnet-mnist-deep-learning-convnet-ep-1/) ที่ใช้ และไม่ใช้ BatchNorm Layer ในการเทรน [Image Classification](https://www.bualabs.com/archives/509/mnist-fastai-resnet18-image-classification-ep-3/) จำแนกชุดข้อมูล [MNIST](https://www.bualabs.com/archives/2215/what-is-mnist/) ชุดเล็ก\n",
        "\n",
        "* จากกราฟท้ายสุด สัดส่วน Activation Map ที่มีค่าน้อย ต่อ Activation Map ทั้งหมด, BatchNorm ทำให้กราฟลดลงเร็วกว่า หมายถึง Activation Map ส่วนใหญ่ มีการ Active เร็วกว่า\n",
        "* จากกราฟ Histogram จะเห็นว่า ConvNet ที่ใช้ BatchNorm สีเหลือง (มีค่ามาก) กระจายไปทั่ว อย่างรวดเร็ว หมายถึง Activation ไม่ได้กระจุกอยู่ใกล้ 0 แต่ Active ไปทั่วทั้ง Layer\n",
        "* จากกราฟ Mean, Std นั้น ConvNet ที่ใช้ BatchNorm ถูกคุมให้ใกล้เคียง Mean=0, Std=1 มากกว่า และ Converge เร็วกว่า ได้ Accuracy ที่มากกว่าในเวลาเทรน 1 Epoch เท่ากัน\n",
        "* ยังมี XNorm อีกหลายแบบ เช่น LayerNorm, InstanceNorm, GroupNorm แต่ประสิทธิภาพไม่ดีเท่า BatchNorm จะอธิบายต่อไป\n",
        "* ถ้า [Batch Size](https://www.bualabs.com/archives/729/what-is-batch-size-in-deep-neural-networks-how-to-adjust-machine-learning-model-accuracy-deep-learning-hyperparameter-tuning-ep-2/) มีขนาดเล็กเกินไปจะทำให้ BatchNorm มีปัญหาได้ เพราะ Mean, Variant จะเหวี่ยงมาก แต่สามารถแก้ได้ด้วย RunningBatchNorm จะอธิบายต่อไป\n",
        "* อันนี้เป็นการเปรียบเทียบคร่าว ๆ ยังมีอีกหลายปัจจัยที่อยู่ภายใน API ที่เพิ่มประสิทธิภาพโดยอัตโนมัติ จะอธิบายต่อไป"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWcASWNpvXRm",
        "colab_type": "text"
      },
      "source": [
        "# Credit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmuDkicxvXWw",
        "colab_type": "text"
      },
      "source": [
        "* https://course.fast.ai/videos/?lesson=10\n",
        "* http://yann.lecun.com/exdb/mnist/\n",
        "* https://www.bualabs.com/archives/509/mnist-fastai-resnet18-image-classification-ep-3/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxJPCXjEvvl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}