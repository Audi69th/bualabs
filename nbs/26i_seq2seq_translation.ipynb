{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "26i_seq2seq_translation.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XlQtoavmlNzL"
      },
      "source": [
        "ใน ep นี้เราจะ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CzApwnjVlKxC"
      },
      "source": [
        "# 0. Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0WcUkQRak7e6",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MGOPzh9vCLJh"
      },
      "source": [
        "Install Library ที่จำเป็น"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o0UgDCGLhby7",
        "outputId": "0b171ff2-0223-4dfb-8e2a-e3c917734f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## Colab\n",
        "! curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Ne5kVMzs9a",
        "colab_type": "text"
      },
      "source": [
        "เช็ค GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cQiYFoC4C8hy",
        "outputId": "a02d40cc-a5ad-44ea-efbf-0e8767bf3625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec 16 09:20:14 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3VxLNfAElR29"
      },
      "source": [
        "# 1. Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nGm02SG0CQrq"
      },
      "source": [
        "Import Library ที่จะใช้ ในที่นี้คือ fastai และ fastai.text "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OORH3obdk-wS",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.callbacks.mem import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nmZehcHclZyM",
        "colab": {}
      },
      "source": [
        "# import fastai.utils.collect_env\n",
        "# fastai.utils.collect_env.show_install()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEbTrCXdBkEG",
        "colab_type": "text"
      },
      "source": [
        "สำหรับ [Google Colab](https://www.bualabs.com/archives/1687/what-is-colab-open-jupyter-notebook-in-github-on-google-colab-create-open-in-colab-button-colab-ep-1/) เราจะกำหนด path ที่เก็บ DataSet และ Mount Google Drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOLkyx3DcL_k",
        "colab_type": "code",
        "outputId": "cae9cd9e-90d1-4d22-a9fa-c1b6650abea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "dataset = '26i-giga-fren'\n",
        "\n",
        "# Google Colab\n",
        "config_path = Path('/content/drive')\n",
        "data_path_base = Path('/content/datasets/')\n",
        "\n",
        "data_path = data_path_base/dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(str(config_path))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pv3eV6oElZD2"
      },
      "source": [
        "# 2. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_9kLpiZj_Rd6"
      },
      "source": [
        "ในเคสนี้เราจะใช้ Human Numbers คือ รายการตัวเลข เขียนเป็นภาษาอังกฤษ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkPHmMH9thma",
        "colab_type": "code",
        "outputId": "1945e7b2-8a90-4a7b-baa4-39a4e5ed4c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_path"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/datasets/26i-giga-fren')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdNLyWa-elkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a382f16-ccf5-422b-99ab-ed6be8d9c0c0"
      },
      "source": [
        "! wget https://s3.amazonaws.com/fast-ai-nlp/giga-fren.tgz -P {data_path}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-16 09:22:10--  https://s3.amazonaws.com/fast-ai-nlp/giga-fren.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.4.22\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.4.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2598183296 (2.4G) [application/x-tar]\n",
            "Saving to: ‘/content/datasets/26i-giga-fren/giga-fren.tgz’\n",
            "\n",
            "giga-fren.tgz       100%[===================>]   2.42G  16.6MB/s    in 2m 32s  \n",
            "\n",
            "2019-12-16 09:24:43 (16.3 MB/s) - ‘/content/datasets/26i-giga-fren/giga-fren.tgz’ saved [2598183296/2598183296]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewedr1hzenKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! tar xf {data_path}/giga-fren.tgz -C {data_path}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLe6xN8Vepnv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6535e4f9-9dc0-454f-b56d-d6eed8486f4d"
      },
      "source": [
        "path = data_path/'giga-fren'\n",
        "path.ls()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/datasets/26i-giga-fren/giga-fren/cc.en.300.bin'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/models'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/giga-fren.release2.fixed.fr'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/giga-fren.release2.fixed.en'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/questions_easy.csv'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/cc.fr.300.bin'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/data_save.pkl')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxz7A6FIe3Fi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ec004201-b8f1-47f8-d4d3-4e33d1ed0dbc"
      },
      "source": [
        "! head {path}/giga-fren.release2.fixed.en"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Changing Lives | Changing Society | How It Works | Technology Drives Change Home | Concepts | Teachers | Search | Overview | Credits | HHCC Web | Reference | Feedback Virtual Museum of Canada Home Page\n",
            "Site map\n",
            "Feedback\n",
            "Credits\n",
            "Français\n",
            "What is light ?\n",
            "The white light spectrum Codes in the light The electromagnetic spectrum Emission spectra Absorption spectra Light-years Light pollution\n",
            "The sky of the first inhabitants A contemporary vison of the Universe Astronomy for everyone\n",
            "Cartoon\n",
            "Links\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEvJiJCXgqmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c0ea290b-708c-4baf-8f41-15f9064c859d"
      },
      "source": [
        "! head {path}/giga-fren.release2.fixed.fr"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il a transformé notre vie | Il a transformé la société | Son fonctionnement | La technologie, moteur du changement Accueil | Concepts | Enseignants | Recherche | Aperçu | Collaborateurs | Web HHCC | Ressources | Commentaires Musée virtuel du Canada\n",
            "Plan du site\n",
            "Rétroaction\n",
            "Crédits\n",
            "English\n",
            "Qu’est-ce que la lumière?\n",
            "La découverte du spectre de la lumière blanche Des codes dans la lumière Le spectre électromagnétique Les spectres d’émission Les spectres d’absorption Les années-lumière La pollution lumineuse\n",
            "Le ciel des premiers habitants La vision contemporaine de l'Univers L’astronomie pour tous\n",
            "Bande dessinée\n",
            "Liens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UyLr_W5gtig",
        "colab_type": "text"
      },
      "source": [
        "# 3. Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHM-gAPNvXhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readfile(d): return [o.strip() for o in open(path/d).readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziNRLy78v2HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fr = readfile(path/'giga-fren.release2.fixed.fr')\n",
        "# len(fr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBm18b60wDu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# en = readfile(path/'giga-fren.release2.fixed.en')\n",
        "# len(en)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaWUtpnahdFg",
        "colab_type": "text"
      },
      "source": [
        "ใช้ [RegEx](https://www.bualabs.com/archives/3070/what-is-regular-expression-regex-regexp-teach-how-to-regex-python-nlp-ep-7/) สกัด เอาเฉพาะประโยคคำถามภาษาอังกฤษออกมา ที่ขึ้นต้นด้วย \"Wh\" และ ลงท้ายด้วย \"?\" และประโยคภาษาฝรั่งเศสที่คู่กัน ที่ลงท้ายด้วย ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orTLOsFThMco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
        "re_fq = re.compile('^([^?.!]+\\?)')\n",
        "en_fname = path/'giga-fren.release2.fixed.en'\n",
        "fr_fname = path/'giga-fren.release2.fixed.fr'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz9fvxgykPtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = ((re_eq.search(eq), re_fq.search(fq))\n",
        "            for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
        "qs = [(e.group(), f.group()) for e, f in lines if e and f]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBFNoItckz82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qs = [(q1, q2) for q1, q2 in qs]\n",
        "\n",
        "df = pd.DataFrame({'fr': [q[1] for q in qs], 'en': [q[0] for q in qs]}, columns=['en', 'fr'])\n",
        "df.to_csv(path/'questions_easy.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4iCNPYBlxz8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7d604813-8688-467f-d3a2-0b0ab0399f4e"
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/datasets/26i-giga-fren/giga-fren/cc.en.300.bin'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/models'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/giga-fren.release2.fixed.fr'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/giga-fren.release2.fixed.en'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/questions_easy.csv'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/cc.fr.300.bin'),\n",
              " PosixPath('/content/datasets/26i-giga-fren/giga-fren/data_save.pkl')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYK1xIZYgaHf",
        "colab_type": "text"
      },
      "source": [
        "DataBunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maHUUpB8gcbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a766d202-1283-45c0-9100-40bd6ae17008"
      },
      "source": [
        "df = pd.read_csv(path/'questions_easy.csv')\n",
        "df.head()"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is light ?</td>\n",
              "      <td>Qu’est-ce que la lumière?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who are we?</td>\n",
              "      <td>Où sommes-nous?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where did we come from?</td>\n",
              "      <td>D'où venons-nous?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What would we do without it?</td>\n",
              "      <td>Que ferions-nous sans elle ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the absolute location (latitude and lo...</td>\n",
              "      <td>Quelle sont les coordonnées (latitude et longi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en                                                 fr\n",
              "0                                    What is light ?                          Qu’est-ce que la lumière?\n",
              "1                                        Who are we?                                    Où sommes-nous?\n",
              "2                            Where did we come from?                                  D'où venons-nous?\n",
              "3                       What would we do without it?                       Que ferions-nous sans elle ?\n",
              "4  What is the absolute location (latitude and lo...  Quelle sont les coordonnées (latitude et longi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaQ71XfWgh6n",
        "colab_type": "text"
      },
      "source": [
        "เพื่อให้ง่ายขึ้น เราจะแปลงเป็นตัวเล็กให้หมด"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_1MfgWUh9wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['en'] = df['en'].apply(lambda x: x.lower())\n",
        "df['fr'] = df['fr'].apply(lambda x: x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQjj0jeeiXnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d1029b3b-7106-4b12-b496-4f070973d9d8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what is light ?</td>\n",
              "      <td>qu’est-ce que la lumière?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>who are we?</td>\n",
              "      <td>où sommes-nous?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>where did we come from?</td>\n",
              "      <td>d'où venons-nous?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what would we do without it?</td>\n",
              "      <td>que ferions-nous sans elle ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what is the absolute location (latitude and lo...</td>\n",
              "      <td>quelle sont les coordonnées (latitude et longi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  en                                                 fr\n",
              "0                                    what is light ?                          qu’est-ce que la lumière?\n",
              "1                                        who are we?                                    où sommes-nous?\n",
              "2                            where did we come from?                                  d'où venons-nous?\n",
              "3                       what would we do without it?                       que ferions-nous sans elle ?\n",
              "4  what is the absolute location (latitude and lo...  quelle sont les coordonnées (latitude et longi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L742mP1h3cCh",
        "colab_type": "text"
      },
      "source": [
        "ประกาศฟังก์ชัน เรียงรวมข้อมูล ใส่ padding และ เรียงย้อนจากหลังมาหน้า ตามที่กำหนด"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTa2IGaD2fWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
        "    samples = to_data(samples)\n",
        "    max_len_x, max_len_y = max([len(s[0]) for s in samples]), max([len(s[1]) for s in samples])\n",
        "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
        "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
        "\n",
        "    if backwards: pad_first = not pad_first\n",
        "    for i, s in enumerate(samples): \n",
        "        if pad_first:\n",
        "            res_x[i, -len(s[0]):], res_y[i, -len(s[1]):] = LongTensor(s[0]), LongTensor(s[1])\n",
        "        else:\n",
        "            res_x[i, :len(s[0]):], res_y[i, :len(s[1]):] = LongTensor(s[0]), LongTensor(s[1])\n",
        "    if backwards: res_x, res_y = res_x.flip(1), res_y.flip(1)\n",
        "    return res_x, res_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QapwAd2biYjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqDataBunch(TextDataBunch):\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', \n",
        "               bs:int=32, val_bs:int=None, pad_idx=1, dl_tfms=None, \n",
        "               pad_first=False, device:torch.device=None, no_check:bool=False, \n",
        "               backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
        "\n",
        "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
        "        val_bs = ifnone(val_bs, bs)\n",
        "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, \n",
        "                             pad_first=pad_first, backwards=backwards)\n",
        "        train_sampler = SortishSampler(datasets[0].x, \n",
        "                                       key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
        "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
        "        dataloaders = [train_dl]\n",
        "        for ds in datasets[1:]:\n",
        "            lengths = [len(t) for t in ds.x.items]\n",
        "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
        "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
        "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZu42VYS1u82",
        "colab_type": "text"
      },
      "source": [
        "Random Sampler แต่ให้เรียงภายใน Batch เนื่องจากประโยคควรเรียง"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieRoRVDDrogx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SortishSampler??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TEIGlxzr0zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqTextList(TextList):\n",
        "    _bunch = Seq2SeqDataBunch\n",
        "    _label_cls = TextList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cXEC5qmwf8m",
        "colab_type": "text"
      },
      "source": [
        "กำหนด Data Pipeline ด้วย Data Block API ให้ข้อมูลตัวอย่าง x เป็นประโยคภาษาฝรั่งเศส และ Label y เป็นประโยคภาษาอังกฤษ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww-Rf3J0wBU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3ac4cb93-e39c-40f6-821e-4e02520764b3"
      },
      "source": [
        "src = Seq2SeqTextList.from_df(df, path=path, cols='fr').split_by_rand_pct(seed=42).label_from_df(cols='en', label_cls=TextList)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVtvRbdL0ElO",
        "colab_type": "text"
      },
      "source": [
        "ดูตำแหน่ง Token ที่ความยาว 90% \n",
        "\n",
        "ได้โดยเฉลี่ยไม่เกิน 28 Token สำหรับภาษาฝรั่งเศส และ 23 Token สำหรับ ภาษาอังกฤษ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPev7JBwwU8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce5b868c-9788-4b53-8a19-c5d7eeecb822"
      },
      "source": [
        "np.percentile([len(o) for o in src.train.x.items] + [len(o) for o in src.valid.x.items], 90)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFuTzxRRxG8c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1690ccbf-acfb-4f76-dce8-df29fea579e7"
      },
      "source": [
        "np.percentile([len(o) for o in src.train.y.items] + [len(o) for o in src.valid.y.items], 90)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ngQG4tq0mwf",
        "colab_type": "text"
      },
      "source": [
        "เพื่อความง่าย เราจะลบ ประโยคที่ยาวกว่า 30 Token ในภาษาใดภาษาหนึ่ง (ไม่ถึง 10%) ทิ้งไป"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azdn368z0u9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src = src.filter_by_func(lambda x, y: len(x) > 30 or len(y) > 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RNsStku1DFk",
        "colab_type": "text"
      },
      "source": [
        "เหลือ 48350 คู่ประโยค"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_i8-lC08rO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ac60260-b82d-4078-c218-e2cebcc0bb3e"
      },
      "source": [
        "len(src.train) + len(src.valid)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48350"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moi0JGOM1E1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = src.databunch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I35smSDd9FSv",
        "colab_type": "text"
      },
      "source": [
        "Save ไว้ก่อน คราวหน้าจะได้ไม่ต้อง Preprocess ใหม่"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LY4D3F_1a4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.save()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-96BbAjk1735",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "3846fe8e-5373-4562-d8c4-8d0b840a64ba"
      },
      "source": [
        "data"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqDataBunch;\n",
              "\n",
              "Train: LabelList (38704 items)\n",
              "x: Seq2SeqTextList\n",
              "xxbos qu’est - ce que la lumière ?,xxbos où sommes - nous ?,xxbos d'où venons - nous ?,xxbos que ferions - nous sans elle ?,xxbos quel est le groupe autochtone principal sur l’île de vancouver ?\n",
              "y: TextList\n",
              "xxbos what is light ?,xxbos who are we ?,xxbos where did we come from ?,xxbos what would we do without it ?,xxbos what is the major aboriginal group on vancouver island ?\n",
              "Path: /content/datasets/26i-giga-fren/giga-fren;\n",
              "\n",
              "Valid: LabelList (9646 items)\n",
              "x: Seq2SeqTextList\n",
              "xxbos quels pourraient être les effets sur l’instrument de xxunk et sur l’aide humanitaire qui ne sont pas co - xxunk ?,xxbos quand la source primaire a - t - elle été créée ?,xxbos pourquoi tant de soldats ont - ils fait xxunk de ne pas voir ce qui s'est passé le 4 et le 16 mars ?,xxbos quels sont les taux d'impôt sur le revenu au canada pour 2007 ?,xxbos pourquoi le programme devrait - il intéresser les employeurs et les fournisseurs de services ?\n",
              "y: TextList\n",
              "xxbos what would be the resulting effects on the pre - accession instrument and humanitarian aid that are not co - decided ?,xxbos when was the primary source created ?,xxbos why did so many soldiers look the other way in relation to the incidents of march 4th and march xxunk ?,xxbos what are the income tax rates in canada for 2007 ?,xxbos why is the program good for employers and service providers ?\n",
              "Path: /content/datasets/26i-giga-fren/giga-fren;\n",
              "\n",
              "Test: None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGEA9Km78-9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b8c13b9-7b46-4387-ddb3-a5967188a9fa"
      },
      "source": [
        "path"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/datasets/26i-giga-fren/giga-fren')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9XRY8Sv9T9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt4p0UJt9Wsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "096521f2-4216-45f2-afc5-c8c6f358bcb5"
      },
      "source": [
        "data.show_batch()"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos quels services offrez - vous aux résidents , par l'entremise de votre propre organisation , par l'entremise de liens / partenariats avec des organismes communautaires ou les deux ?</td>\n",
              "      <td>xxbos which of the following services do you offer to residents either through your own organization or through linkages and / or partnerships with community agencies or both ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos quelles initiatives ont été prises , conformément aux recommandations précédentes du comité , pour sensibiliser tant les hommes que les femmes à la contraception et aux méthodes xxunk ?</td>\n",
              "      <td>xxbos what steps have been taken , in line with the committee ’s previous recommendations , to raise awareness about contraception and xxunk methods among both men and women ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos qu’en est - il d’un leader qui ne possède que deux de ces caractéristiques ou de celui qui ne manifeste que de temps en temps certains comportements xxunk ?</td>\n",
              "      <td>xxbos what if a leader xxunk only two of the factors ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos quels mécanismes d'évaluation , de surveillance ou de responsabilisation sont en place pour l'étude de cas , tant dans le cadre de l'initiative qu'à l'intérieur de votre organisation ?</td>\n",
              "      <td>xxbos what evaluation , monitoring or other accountability mechanisms are in place for this work , within the initiative and within your organization ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos quelles sont les hypothèses , selon la définition actuelle du développement , do nt les pays en développement sont censés s'inspirer pour réformer leurs systèmes de politique sociale ?</td>\n",
              "      <td>xxbos what are the assumptions in the current understanding of development that developing countries are expected to accommodate in reforming their social - policy systems ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I0CEK5a9ZYY",
        "colab_type": "text"
      },
      "source": [
        "# 4. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WY3fkwB9gfB",
        "colab_type": "text"
      },
      "source": [
        "แทนที่จะเทรนแต่ต้นทั้งหมด เราจะใช้ Transfer Learning เพื่อประหยัดเวลา และเพิ่มประสิทธิภาพ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVrwT8k9HomY",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pnqfA2dHpV9",
        "colab_type": "text"
      },
      "source": [
        "โดยในส่วนของ Word Embedding เราจะใช้ Pre-trained Word Vector จาก FastText ที่เทรนด้วยข้อมูลจาก Common Crawl และ Wikipedia ด้วยวิธี Continuous Bag of Words (CBOW) จะอธิบายต่อไป"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgegKz2H-Sy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "20e399f4-374f-45a0-d767-9837b4aff57d"
      },
      "source": [
        "! pip install fasttext"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.17.4)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.4.3)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (42.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mPyDZBL_lXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fasttext as ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOb4GtVk_tPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fbbe8704-6f8b-4d03-d479-d8eb7bab318e"
      },
      "source": [
        "# ! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz -P {path}\n",
        "# ! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz -P {path}"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-16 12:02:59--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘/content/datasets/26i-giga-fren/giga-fren/cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  11.9MB/s    in 6m 7s   \n",
            "\n",
            "2019-12-16 12:09:07 (11.7 MB/s) - ‘/content/datasets/26i-giga-fren/giga-fren/cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n",
            "--2019-12-16 12:09:09--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4496886212 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘/content/datasets/26i-giga-fren/giga-fren/cc.fr.300.bin.gz’\n",
            "\n",
            "cc.fr.300.bin.gz    100%[===================>]   4.19G  12.4MB/s    in 5m 48s  \n",
            "\n",
            "2019-12-16 12:14:59 (12.3 MB/s) - ‘/content/datasets/26i-giga-fren/giga-fren/cc.fr.300.bin.gz’ saved [4496886212/4496886212]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5XarQIL_0yU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "a089a176-90e3-4f89-a120-5f48ea9b45ea"
      },
      "source": [
        "# ! gunzip {path}/cc.en.300.bin.gz\n",
        "# ! gunzip {path}/cc.fr.300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: /content/datasets/26i-giga-fren/giga-fren/cc.en.300.bin already exists; do you wish to overwrite (y or n)? "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUxfSvYG_3Ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fr_vecs = ft.load_model(str((path/'cc.fr.300.bin')))\n",
        "en_vecs = ft.load_model(str((path/'cc.en.300.bin')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M_oTBg1B_s9",
        "colab_type": "text"
      },
      "source": [
        "ประกาศฟังก์ชัน สร้าง Embedding จาก Pre-trained Vector และเติมค่า Vector คำศัพท์ที่ขาดหายไปด้วย ค่า Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OA2eE6fBbnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_emb(vecs, itos, em_sz=300, multi=1.):\n",
        "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
        "    wgts = emb.weight.data\n",
        "    vec_dic = {w: vecs.get_word_vector(w) for w in vecs.get_words()}\n",
        "    miss = []\n",
        "    for i, w in enumerate(itos):\n",
        "        try: wgts[i] = tensor(vec_dic[w])\n",
        "        except: miss.append(w)\n",
        "    return emb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9ZvPUGlDG-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_enc = create_emb(fr_vecs, data.x.vocab.itos)\n",
        "emb_dec = create_emb(en_vecs, data.y.vocab.itos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv_hedZYDWvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_enc.weight.size(), emb_dec.weight.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40jGkItlDjLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = config_path/'My Drive/models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQgpS_PYD31v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(emb_enc, model_path/'fr_emb.pth')\n",
        "torch.save(emb_dec, model_path/'en_emb.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Yzv7xIERTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_enc = torch.load(model_path/'fr_emb.pth')\n",
        "emb_dec = torch.load(model_path/'en_emb.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U3ye5p4EGG6",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Sequence to Sequence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcE7oDyLHyB-",
        "colab_type": "text"
      },
      "source": [
        "โมเดลของเราจะแบ่งเป็น 2 ส่วนคือ Encoder แปลงข้อความภาษาอังกฤษ เป็น Vector และ Coder ที่จะ Generate ข้อความภาษาอังกฤษ จาก Vector นั้น\n",
        "\n",
        "เนื่องจากเราไม่ได้ Transfer Learning ใด ๆ ทั้งสิ้นยกเว้น Embedding ทำให้ Layer ของ GRU และ Linear จะถูก [Initialize](https://www.bualabs.com/archives/2633/what-is-lsuv-layer-sequential-unit-variance-initialization-difference-kaiming-initialization-convnet-ep-6/) ด้วยค่า Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gdBt0F2IIht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqRNN(nn.Module):\n",
        "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
        "        super().__init__()\n",
        "        self.nl, self.nh, self.out_sl = nl, nh, out_sl\n",
        "        self.bos_idx, self.pad_idx = bos_idx, pad_idx\n",
        "        self.em_sz_enc = emb_enc.embedding_dim\n",
        "        self.em_sz_dec = emb_dec.embedding_dim\n",
        "        self.voc_sz_dec = emb_dec.num_embeddings\n",
        "\n",
        "        self.emb_enc = emb_enc\n",
        "        self.emb_enc_drop = nn.Dropout(0.15)\n",
        "        self.gru_enc = nn.GRU(self.em_sz_enc, nh, num_layers=nl, \n",
        "                              dropout=0.25, batch_first=True)\n",
        "        self.out_enc = nn.Linear(nh, self.em_sz_dec, bias=False)\n",
        "\n",
        "        self.emb_dec = emb_dec\n",
        "        self.gru_dec = nn.GRU(self.em_sz_dec, self.em_sz_dec, num_layers=nl, \n",
        "                              dropout=0.1, batch_first=True)\n",
        "        self.out_drop = nn.Dropout(0.35)\n",
        "        self.out = nn.Linear(self.em_sz_dec, self.voc_sz_dec)\n",
        "        self.out.weight.data = self.emb_dec.weight.data\n",
        "\n",
        "    def encoder(self, bs, inp):\n",
        "        h = self.initHidden(bs)\n",
        "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
        "        _, h = self.gru_enc(emb, h)\n",
        "        h = self.out_enc(h)\n",
        "        return h\n",
        "\n",
        "    def decoder(self, dec_inp, h):\n",
        "        emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
        "        outp, h = self.gru_dec(emb, h)\n",
        "        outp = self.out(self.out_drop(outp[:, 0]))\n",
        "        return h, outp\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        bs, sl = inp.size()\n",
        "        h = self.encoder(bs, inp)\n",
        "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
        "\n",
        "        res = []\n",
        "        for i in range(self.out_sl):\n",
        "            h, outp = self.decoder(dec_inp, h)\n",
        "            dec_inp = outp.max(1)[1]\n",
        "            res.append(outp)\n",
        "            if (dec_inp==self.pad_idx).all(): break\n",
        "        return torch.stack(res, dim=1)\n",
        "    \n",
        "    def initHidden(self, bs):\n",
        "        return one_param(self).new_zeros(self.nl, bs, self.nh)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auEbnjrCKkQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = next(iter(data.valid_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XyZ4Nr8NJnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFy-7zNoNKbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = Seq2SeqRNN(emb_enc, emb_dec, 256, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTT_JEjvNRCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlBIVDE6NcJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(xb[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dEEwyliNpN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = rnn.encoder(64, xb.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZxfI9C-NshB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IMx8nVONt3t",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek8-1TbiNy9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_loss(out, targ, pad_idx=1):\n",
        "    bs, targ_len = targ.size()\n",
        "    _, out_len, vs = out.size()\n",
        "    if targ_len > out_len: out = F.pad(out, (0, 0, 0, targ_len-out_len, 0, 0), value=pad_idx)\n",
        "    if out_len > targ_len: targ = F.pad(targ, (0, out_len-targ_len, 0, 0), value=pad_idx)\n",
        "    return CrossEntropyFlat()(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxZBeP30TJdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_acc(out, targ, pad_idx=1):\n",
        "    bs, targ_len = targ.size()\n",
        "    _, out_len, vs = out.size()\n",
        "    if targ_len > out_len: out = F.pad(out, (0, 0, 0, targ_len-out_len, 0, 0), value=pad_idx)\n",
        "    if out_len > targ_len: targ = F.pad(targ, (0, out_len-targ_len, 0, 0), value=pad_idx)\n",
        "    out = out.argmax(2)\n",
        "    return (out == targ).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp-AVVnuOfVw",
        "colab_type": "text"
      },
      "source": [
        "# 5. Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BTZcF6WWIRW",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 Train โมเดลที่สร้างไว้ด้านบน"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUX6ZqNgOh3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, rnn, loss_func=seq2seq_loss, callback_fns=[ShowGraph], metrics=[seq2seq_acc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZB4xiK8OnWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(suggest=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q21Cb84CWWQl",
        "colab_type": "text"
      },
      "source": [
        "แต่ Accuracy เป็น Metrics ที่ไม่ค่อยเหมาะสำหรับงาน Translation สักเท่าไร"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBVshwe_Oqpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(4, 3e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7mh-5H_SS55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del fr_vecs\n",
        "del en_vecs\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEoDvDLGTMYl",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 Bleu Metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQktkM5HWjq4",
        "colab_type": "text"
      },
      "source": [
        "ในงาน Translation เนื่องจากภาษามนุษย์นั้นดิ้นได้ สมมติให้คน 2 คนแปลข้อความเดียวกัน เป็นไปได้ยากที่จะแปลออกมาเป็นประโยคเดียวกันตรงกันทุกคำ จึงไม่นิยมใช้ Metric ที่เปรียบเทียบคำต่อคำตรง ๆ แบบ Accuracy แต่นิยมใช้ Metric ที่เรียกว่า Bleu \n",
        "\n",
        "Bleu Score คืออะไร จะอธิบายต่อไป"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j--QdXcqWuPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NGram():\n",
        "    def __init__(self, ngram, max_n=50000): self.ngram, self.max_n = ngram, max_n\n",
        "    def __eq__(self, other): \n",
        "        if len(self.ngram) != len(other.ngram): return False\n",
        "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
        "    def __hash__(self): return int(sum([o * self.max_n**i for i, o in enumerate(self.ngram)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAyHUFt9W0Bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_grams(x, n, max_n=5000):\n",
        "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7cEmT3mW0JU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_correct_ngrams(pred, targ, n, max_n=5000): \n",
        "    pred_grams, targ_grams = get_grams(pred, n, max_n=max_n), get_grams(targ, n, max_n=max_n)\n",
        "    pred_cnt, targ_cnt = Counter(pred_grams), Counter(targ_grams)\n",
        "    return sum([min(c, targ_cnt[g]) for g, c in pred_cnt.items()]), len(pred_grams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPE8nHXkW0PY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CorpusBLEU(Callback):\n",
        "    def __init__(self, vocab_sz):\n",
        "        self.vocab_sz = vocab_sz\n",
        "        self.name = 'bleu'\n",
        "\n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.pred_len, self.targ_len, self.corrects, self.counts = 0, 0, [0]*4, [0]*4\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        last_output = last_output.argmax(dim=-1)\n",
        "        for pred, targ in zip(last_output.cpu().numpy(), last_target.cpu().numpy()):\n",
        "            self.pred_len += len(pred)\n",
        "            self.targ_len += len(targ)\n",
        "            for i in range(4):\n",
        "                c, t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
        "                self.corrects[i] += c\n",
        "                self.counts[i] += t\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        precs = [c/t for c, t in zip(self.corrects, self.counts)]\n",
        "        len_penalty = exp(1 - self.targ_len / self.pred_len) if self.pred_len < self.targ_len else 1\n",
        "        bleu = len_penalty * ((precs[0] * precs[1] * precs[2] * precs[3]) ** 0.25)\n",
        "        return add_metrics(last_metrics, bleu)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emIyjSzoW0Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, rnn, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))], callback_fns=[ShowGraph])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeJBblKqW0bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvgpYbyrfCCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(4, 3e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX1_9yoofBuz",
        "colab_type": "text"
      },
      "source": [
        "## 6. View Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5KtK00ZfBlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
        "    learn.model.eval()\n",
        "    inputs, targets, outputs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in progress_bar(learn.dl(ds_type)):\n",
        "            out = learn.model(xb)\n",
        "            for x, y, z in zip(xb, yb, out):\n",
        "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
        "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
        "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
        "    return inputs, targets, outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pe7LGBytwTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs, targets, outputs = get_predictions(learn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWQkIreFt16R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 999\n",
        "inputs[idx], targets[idx], outputs[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KXEZ7c9twHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 2222\n",
        "inputs[idx], targets[idx], outputs[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85nuJne7ZK14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 3333\n",
        "inputs[idx], targets[idx], outputs[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fuSYoHOZK8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 4444\n",
        "inputs[idx], targets[idx], outputs[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgQJKHtwG1ec",
        "colab_type": "text"
      },
      "source": [
        "ปัญหาคือ ถึงโมเดลจะเริ่มต้นได้ดี แต่แล้วก็จะออกทะเลไปเรื่อย ๆ กลายเป็นคำซ้ำ ๆ ไปจนจบ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P29cHUItv8X",
        "colab_type": "text"
      },
      "source": [
        "# 5/2 Teacher Forcing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhz0JMPDGJIO",
        "colab_type": "text"
      },
      "source": [
        "ในการเทรน Decoder ที่เป็น RNN ตามปกติจะนำ Output มา Feed กลับเป็น Input สำหรับคำต่อไป แต่ถ้าโมเดลยังไม่ค่อยเก่ง Predict Output ออกมาผิด แล้วเรานำ Output ที่ผิดนั้นไป Feed กลับมาเป็น Input ทำให้ Output ต่อ ๆ ไป ผิดเป็นโดมิโนไปหมด วิธีหนึ่งที่จะช่วยให้โมเดล เรียนรู้ได้ดีขึ้น คือ Teacher Forcing\n",
        "\n",
        "Teacher Forcing คือ การเทรนด้วยแทนที่ จะ Feed Output จากโมเดล เป็น Input อย่างเดียว เราจะ Feed ผสม  Output ที่ถูกต้อง (Label) กับ Output ของโมเดล (Prediction) เข้าด้วยกัน ตามสัดส่วนที่กำหนด แล้วค่อย ๆ ปรับสัดส่วนเพิ่ม Output จากโมเดลขึ้นเรื่อย ๆ ลด Label ลง จนเทรนด้วย Output อย่างเดียว"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcz-8PYWF4kU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TeacherForcing(LearnerCallback):\n",
        "    def __init__(self, learn, end_epoch):\n",
        "        super().__init__(learn)\n",
        "        self.end_epoch = end_epoch\n",
        "    \n",
        "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
        "        if train: return {'last_input': [last_input, last_target]}\n",
        "\n",
        "    def on_epoch_begin(self, epoch, **kwargs):\n",
        "        self.learn.model.pr_force = 1 - epoch/self.end_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAqwOUh6F4ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqRNN_tf(nn.Module):\n",
        "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
        "        super().__init__()\n",
        "        self.nl, self.nh, self.out_sl = nl, nh, out_sl\n",
        "        self.bos_idx, self.pad_idx = bos_idx, pad_idx\n",
        "        self.em_sz_enc = emb_enc.embedding_dim\n",
        "        self.em_sz_dec = emb_dec.embedding_dim\n",
        "        self.voc_sz_dec = emb_dec.num_embeddings\n",
        "\n",
        "        self.emb_enc = emb_enc\n",
        "        self.emb_enc_drop = nn.Dropout(0.15)\n",
        "        self.gru_enc = nn.GRU(self.em_sz_enc, nh, num_layers=nl, \n",
        "                              dropout=0.25, batch_first=True)\n",
        "        self.out_enc = nn.Linear(nh, self.em_sz_dec, bias=False)\n",
        "\n",
        "        self.emb_dec = emb_dec\n",
        "        self.gru_dec = nn.GRU(self.em_sz_dec, self.em_sz_dec, num_layers=nl, \n",
        "                              dropout=0.1, batch_first=True)\n",
        "        self.out_drop = nn.Dropout(0.35)\n",
        "        self.out = nn.Linear(self.em_sz_dec, self.voc_sz_dec)\n",
        "        self.out.weight.data = self.emb_dec.weight.data\n",
        "\n",
        "    def encoder(self, bs, inp):\n",
        "        h = self.initHidden(bs)\n",
        "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
        "        _, h = self.gru_enc(emb, h)\n",
        "        h = self.out_enc(h)\n",
        "        return h\n",
        "\n",
        "    def decoder(self, dec_inp, h):\n",
        "        emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
        "        outp, h = self.gru_dec(emb, h)\n",
        "        outp = self.out(self.out_drop(outp[:, 0]))\n",
        "        return h, outp\n",
        "    \n",
        "    def forward(self, inp, targ=None):\n",
        "        bs, sl = inp.size()\n",
        "        h = self.encoder(bs, inp)\n",
        "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
        "\n",
        "        res = []\n",
        "        for i in range(self.out_sl):\n",
        "            h, outp = self.decoder(dec_inp, h)\n",
        "            dec_inp = outp.max(1)[1]\n",
        "            res.append(outp)\n",
        "            if (dec_inp==self.pad_idx).all(): break\n",
        "            if (targ is not None) and (random.random()<self.pr_force):\n",
        "                if i >= targ.shape[1]: continue\n",
        "                dec_inp = targ[:, i]\n",
        "        return torch.stack(res, dim=1)\n",
        "    \n",
        "    def initHidden(self, bs):\n",
        "        return one_param(self).new_zeros(self.nl, bs, self.nh)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbvY8q51F43p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_enc = torch.load(model_path/'fr_emb.pth')\n",
        "emb_dec = torch.load(model_path/'en_emb.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rpp-q5FF5FO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_tf = Seq2SeqRNN_tf(emb_enc, emb_dec, 256, 30)\n",
        "\n",
        "learn = Learner(data, rnn_tf, loss_func=seq2seq_loss, \n",
        "                metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))], \n",
        "                callback_fns=[ShowGraph, partial(TeacherForcing, end_epoch=3)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d_Spap7F5K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_QF07tWF5Aq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(8, max_lr=3e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXe1rCE0cHXB",
        "colab_type": "text"
      },
      "source": [
        "# 6/2. View Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "77rEbRVNTk-C",
        "colab": {}
      },
      "source": [
        "inputs, targets, outputs = get_predictions(learn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oeDVTPFkZWwj",
        "colab": {}
      },
      "source": [
        "idx = 999\n",
        "inputs[idx], targets[idx], outputs[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f9WT93amZWwr",
        "colab": {}
      },
      "source": [
        "idx = 2222\n",
        "inputs[idx], targets[idx], outputs[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6v7uFenqZWwu",
        "colab": {}
      },
      "source": [
        "idx = 3333\n",
        "inputs[idx], targets[idx], outputs[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xk67HQrWZWwx",
        "colab": {}
      },
      "source": [
        "idx = 4444\n",
        "inputs[idx], targets[idx], outputs[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdYMUS6_F40K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znPxMYlaW0gK",
        "colab_type": "text"
      },
      "source": [
        "# Credit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqd6yzv1W12G",
        "colab_type": "text"
      },
      "source": [
        "* https://www.youtube.com/watch?v=IfsjMg4fLWQ&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=12\n",
        "* https://www.bualabs.com/archives/3103/what-is-recurrent-neural-network-rnn-pytorch-gru-nlp-ep-9/\n",
        "* https://www.bualabs.com/archives/3087/sentiment-classification-deep-learning-imdb-movie-reviews-positive-negative-deep-neural-network-awd-lstm-ulmfit-nlp-ep-8/\n",
        "* https://www.bualabs.com/archives/3060/what-is-n-gram-sentiment-classification-imdb-movie-review-naive-bayes-logistic-regression-nlp-ep-6/\n",
        "* https://ieeexplore.ieee.org/document/6795228/\n",
        "* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "* http://www.statmt.org/wmt15/translation-task.html\n",
        "* https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "* https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213\n",
        "* https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
        "* https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/translation.ipynb\n",
        "* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rOTbow-YqRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}