{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "26j_seq2seq_attention.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XlQtoavmlNzL"
      },
      "source": [
        "ใน ep นี้เราจะเรียนรู้"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CzApwnjVlKxC"
      },
      "source": [
        "# 0. Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0WcUkQRak7e6",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MGOPzh9vCLJh"
      },
      "source": [
        "Install Library ที่จำเป็น"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o0UgDCGLhby7",
        "outputId": "14c21c81-2d66-4e0c-acad-f88b4fdd3547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## Colab\n",
        "! curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Ne5kVMzs9a",
        "colab_type": "text"
      },
      "source": [
        "เช็ค GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cQiYFoC4C8hy",
        "outputId": "90b90fe2-5112-48d2-b950-6ab29d7034da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3VxLNfAElR29"
      },
      "source": [
        "# 1. Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nGm02SG0CQrq"
      },
      "source": [
        "Import Library ที่จะใช้ ในที่นี้คือ fastai และ fastai.text "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OORH3obdk-wS",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.callbacks.mem import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nmZehcHclZyM",
        "colab": {}
      },
      "source": [
        "# import fastai.utils.collect_env\n",
        "# fastai.utils.collect_env.show_install()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEbTrCXdBkEG",
        "colab_type": "text"
      },
      "source": [
        "สำหรับ [Google Colab](https://www.bualabs.com/archives/1687/what-is-colab-open-jupyter-notebook-in-github-on-google-colab-create-open-in-colab-button-colab-ep-1/) เราจะกำหนด path ที่เก็บ DataSet และ Mount Google Drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOLkyx3DcL_k",
        "colab_type": "code",
        "outputId": "a66deddb-e408-469e-e2cc-38f6967696da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "dataset = '26i-giga-fren'\n",
        "\n",
        "## Google Colab\n",
        "config_path = Path('/content/drive')\n",
        "data_path_base = Path('/content/drive/My Drive/datasets/')\n",
        "\n",
        "# ## VM\n",
        "# config_path = Path(os.getenv(\"HOME\"))\n",
        "# data_path_base = Path(os.getenv(\"HOME\")'/datasets/')\n",
        "\n",
        "data_path = data_path_base/dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(str(config_path))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pv3eV6oElZD2"
      },
      "source": [
        "# 2. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_9kLpiZj_Rd6"
      },
      "source": [
        "ในเคสนี้เราจะใช้ giga-fren คือ Giga-word corpus สำหรับแปลภาษาระหว่างภาษาฝรั่งเศส-ภาษาอังกฤษ (French-English) จากงาน WMT2010 รวบรวมโดย Chris Callison-Burch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "91a9baec-dda0-471d-ee9e-e65314592500",
        "id": "fLeB-sQgRhFj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_path"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/My Drive/datasets/26i-giga-fren')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-46vRPLTRlgW"
      },
      "source": [
        "ดูว่ามีไฟล์อะไรบ้าง"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8df721c5-ca31-4036-9291-6694d6041949",
        "id": "eY0UHIoaRlgP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "path = data_path/'giga-fren'\n",
        "path.ls()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/My Drive/datasets/26i-giga-fren/giga-fren/giga-fren.release2.fixed.en'),\n",
              " PosixPath('/content/drive/My Drive/datasets/26i-giga-fren/giga-fren/questions_easy.csv'),\n",
              " PosixPath('/content/drive/My Drive/datasets/26i-giga-fren/giga-fren/.ipynb_checkpoints'),\n",
              " PosixPath('/content/drive/My Drive/datasets/26i-giga-fren/giga-fren/databunch-small-questions.pkl')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UyLr_W5gtig",
        "colab_type": "text"
      },
      "source": [
        "# 3. Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTa2IGaD2fWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
        "    samples = to_data(samples)\n",
        "    max_len_x, max_len_y = max([len(s[0]) for s in samples]), max([len(s[1]) for s in samples])\n",
        "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
        "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
        "\n",
        "    if backwards: pad_first = not pad_first\n",
        "    for i, s in enumerate(samples): \n",
        "        if pad_first:\n",
        "            res_x[i, -len(s[0]):], res_y[i, -len(s[1]):] = LongTensor(s[0]), LongTensor(s[1])\n",
        "        else:\n",
        "            res_x[i, :len(s[0]):], res_y[i, :len(s[1]):] = LongTensor(s[0]), LongTensor(s[1])\n",
        "    if backwards: res_x, res_y = res_x.flip(1), res_y.flip(1)\n",
        "    return res_x, res_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QapwAd2biYjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqDataBunch(TextDataBunch):\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', \n",
        "               bs:int=32, val_bs:int=None, pad_idx=1, dl_tfms=None, \n",
        "               pad_first=False, device:torch.device=None, no_check:bool=False, \n",
        "               backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
        "\n",
        "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
        "        val_bs = ifnone(val_bs, bs)\n",
        "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, \n",
        "                             pad_first=pad_first, backwards=backwards)\n",
        "        train_sampler = SortishSampler(datasets[0].x, \n",
        "                                       key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
        "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
        "        dataloaders = [train_dl]\n",
        "        for ds in datasets[1:]:\n",
        "            lengths = [len(t) for t in ds.x.items]\n",
        "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
        "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
        "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TEIGlxzr0zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqTextList(TextList):\n",
        "    _bunch = Seq2SeqDataBunch\n",
        "    _label_cls = TextList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okKbONI6pNUf",
        "colab_type": "text"
      },
      "source": [
        "โหลด DataBunch ที่สร้างไว้ใน [ep ที่แล้ว Sequence to Sequence RNN Model](https://www.bualabs.com/archives/3134/what-is-sequence-to-sequence-neural-translate-machine-translation-french-to-english-sequence-to-sequence-model-rnn-gru-teacher-forcing-nlp-ep-10/) ขึ้นมา"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4iCNPYBlxz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path, 'databunch-small-questions.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64Fss7Vuu4Un",
        "colab_type": "text"
      },
      "source": [
        "# 4. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk9UkwP68YdP",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE-c37X5wLZf",
        "colab_type": "text"
      },
      "source": [
        "โหลด Embedding ที่สร้างไว้ใน [ep ที่แล้ว Sequence to Sequence RNN Model](https://www.bualabs.com/archives/3134/what-is-sequence-to-sequence-neural-translate-machine-translation-french-to-english-sequence-to-sequence-model-rnn-gru-teacher-forcing-nlp-ep-10/) ขึ้นมา"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQWX57L4otjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = config_path/'My Drive/models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTE9FUGwolsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_enc = torch.load(model_path/'fr_emb.pth')\n",
        "emb_dec = torch.load(model_path/'en_emb.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkgF1Kxg8dbG",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Loss, Metrics and Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z2jBOY18klD",
        "colab_type": "text"
      },
      "source": [
        "Loss Function, Metrics และ Teacher Forcing Callback จาก ep ที่แล้ว"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UE30dNTolxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_loss(out, targ, pad_idx=1):\n",
        "    bs, targ_len = targ.size()\n",
        "    _, out_len, vs = out.size()\n",
        "    if targ_len > out_len: out = F.pad(out, (0, 0, 0, targ_len-out_len, 0, 0), value=pad_idx)\n",
        "    if out_len > targ_len: targ = F.pad(targ, (0, out_len-targ_len, 0, 0), value=pad_idx)\n",
        "    return CrossEntropyFlat()(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63hKeqqDol2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_acc(out, targ, pad_idx=1):\n",
        "    bs, targ_len = targ.size()\n",
        "    _, out_len, vs = out.size()\n",
        "    if targ_len > out_len: out = F.pad(out, (0, 0, 0, targ_len-out_len, 0, 0), value=pad_idx)\n",
        "    if out_len > targ_len: targ = F.pad(targ, (0, out_len-targ_len, 0, 0), value=pad_idx)\n",
        "    out = out.argmax(2)\n",
        "    return (out == targ).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWVJ1fKkwYZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NGram():\n",
        "    def __init__(self, ngram, max_n=50000): self.ngram, self.max_n = ngram, max_n\n",
        "    def __eq__(self, other): \n",
        "        if len(self.ngram) != len(other.ngram): return False\n",
        "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
        "    def __hash__(self): return int(sum([o * self.max_n**i for i, o in enumerate(self.ngram)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTAvGIrowYg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_grams(x, n, max_n=5000):\n",
        "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlR5Q-PTwYnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_correct_ngrams(pred, targ, n, max_n=5000): \n",
        "    pred_grams, targ_grams = get_grams(pred, n, max_n=max_n), get_grams(targ, n, max_n=max_n)\n",
        "    pred_cnt, targ_cnt = Counter(pred_grams), Counter(targ_grams)\n",
        "    return sum([min(c, targ_cnt[g]) for g, c in pred_cnt.items()]), len(pred_grams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjhbbpVdwYtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CorpusBLEU(Callback):\n",
        "    def __init__(self, vocab_sz):\n",
        "        self.vocab_sz = vocab_sz\n",
        "        self.name = 'bleu'\n",
        "\n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.pred_len, self.targ_len, self.corrects, self.counts = 0, 0, [0]*4, [0]*4\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        last_output = last_output.argmax(dim=-1)\n",
        "        for pred, targ in zip(last_output.cpu().numpy(), last_target.cpu().numpy()):\n",
        "            self.pred_len += len(pred)\n",
        "            self.targ_len += len(targ)\n",
        "            for i in range(4):\n",
        "                c, t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
        "                self.corrects[i] += c\n",
        "                self.counts[i] += t\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        precs = [c/t for c, t in zip(self.corrects, self.counts)]\n",
        "        len_penalty = exp(1 - self.targ_len / self.pred_len) if self.pred_len < self.targ_len else 1\n",
        "        bleu = len_penalty * ((precs[0] * precs[1] * precs[2] * precs[3]) ** 0.25)\n",
        "        return add_metrics(last_metrics, bleu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scj2Ma8f8Uda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
        "    learn.model.eval()\n",
        "    inputs, targets, outputs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in progress_bar(learn.dl(ds_type)):\n",
        "            out = learn.model(xb)\n",
        "            for x, y, z in zip(xb, yb, out):\n",
        "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
        "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
        "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
        "    return inputs, targets, outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16-9SfXo86AK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TeacherForcing(LearnerCallback):\n",
        "    def __init__(self, learn, end_epoch):\n",
        "        super().__init__(learn)\n",
        "        self.end_epoch = end_epoch\n",
        "    \n",
        "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
        "        if train: return {'last_input': [last_input, last_target]}\n",
        "\n",
        "    def on_epoch_begin(self, epoch, **kwargs):\n",
        "        self.learn.model.pr_force = 1 - epoch/self.end_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UH_dEPm8Ukg",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 New Model with Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhFWkx5p8Uqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfyUvAsZ8UxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYSdCxsQ8U2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYGpWeWt8U7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UznJfn6h8VB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvgPvpdb8VFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK0c60PP4dsM",
        "colab_type": "text"
      },
      "source": [
        "# 7. สรุป"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXZKouVU4eKI",
        "colab_type": "text"
      },
      "source": [
        "* เราได้เรียนรู้\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkQbNoqb7a9G",
        "colab_type": "text"
      },
      "source": [
        "ตารางสรุป ผลลัพธ์การเทรนโมเดลแบบต่าง ๆ\n",
        "\n",
        "model            | train_loss | valid_loss | seq2seq_acc | bleu\n",
        "-------------------|----------|----------|----------|----------\n",
        "seq2seq            | 2.823382 | 3.826643 | 0.427117 | 0.322879\n",
        "\\+ teacher forcing | 2.678760 |\t3.732396 | 0.439311 | 0.332833\n",
        "\\+ attention       | 1.452292 | 3.420485 | 0.498205 | 0.413232\n",
        "transformer        | 1.913152 | 2.349686 | 0.781749 | 0.612880"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znPxMYlaW0gK",
        "colab_type": "text"
      },
      "source": [
        "# Credit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqd6yzv1W12G",
        "colab_type": "text"
      },
      "source": [
        "* https://www.youtube.com/watch?v=IfsjMg4fLWQ&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=12\n",
        "* https://www.bualabs.com/archives/3134/what-is-sequence-to-sequence-neural-translate-machine-translation-french-to-english-sequence-to-sequence-model-rnn-gru-teacher-forcing-nlp-ep-10/\n",
        "* https://www.bualabs.com/archives/3103/what-is-recurrent-neural-network-rnn-pytorch-gru-nlp-ep-9/\n",
        "* https://www.bualabs.com/archives/3087/sentiment-classification-deep-learning-imdb-movie-reviews-positive-negative-deep-neural-network-awd-lstm-ulmfit-nlp-ep-8/\n",
        "* https://www.bualabs.com/archives/3060/what-is-n-gram-sentiment-classification-imdb-movie-review-naive-bayes-logistic-regression-nlp-ep-6/\n",
        "* http://opus.nlpl.eu/giga-fren.php\n",
        "* https://arxiv.org/abs/1409.3215\n",
        "* https://ieeexplore.ieee.org/document/6795228/\n",
        "* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "* http://www.statmt.org/wmt15/translation-task.html\n",
        "* https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "* https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213\n",
        "* https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
        "* https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/translation.ipynb\n",
        "* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWwHfaeVwzO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}