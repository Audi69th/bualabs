{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "27b_pythainlp_tokenize.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFzF/qgoCMgMVuFjuIpOS6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hroev-q_1koR",
        "colab_type": "text"
      },
      "source": [
        "เนื่องจากภาษาไทย เป็นภาษาที่เขียนติดกันหมด ไม่มีการเว้นคำด้วย Space เหมือนภาษาอังกฤษ ทำให้การตัดคำภาษาไทย หรือ Tokenization มีความซับซ้อน และ การตัดคำที่ถูกต้องมีความสำคัญ ต่อการนำข้อมูลคำศัพท์ ไปประมวลผลต่อ เช่น Feed เข้าโมเดล Machine Learning ต่อไป"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CzApwnjVlKxC"
      },
      "source": [
        "# 0. Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0WcUkQRak7e6",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MGOPzh9vCLJh"
      },
      "source": [
        "Install Library ที่จำเป็น แล้ว Restart Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJyPgTMyBHHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ab8e92d-a776-46f3-9b90-7c28bd64d6a8"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpAhcT3WxGqF",
        "colab_type": "code",
        "outputId": "d8cb1e0a-7f94-46f6-d041-246af26d93db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# dev version\n",
        "# !pip install https://github.com/PyThaiNLP/pythainlp/archive/dev.zip\n",
        "\n",
        "# release version \n",
        "! pip install pythainlp\n",
        "\n",
        "!pip install epitran\n",
        "!pip install sklearn_crfsuite\n",
        "!pip install tensorflow deepcut"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.6/dist-packages (2.1.3)\n",
            "Requirement already satisfied: tqdm>=4.1 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (4.28.1)\n",
            "Requirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.3.1.1)\n",
            "Requirement already satisfied: nltk>=3.3 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (3.4.5)\n",
            "Requirement already satisfied: tinydb>=3.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (3.15.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /tensorflow-2.1.0/python3.6 (from pythainlp) (2.22.0)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from nltk>=3.3->pythainlp) (1.14.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.22.0->pythainlp) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.22.0->pythainlp) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.22.0->pythainlp) (1.25.7)\n",
            "Requirement already satisfied: epitran in /usr/local/lib/python3.6/dist-packages (1.8)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.6/dist-packages (from epitran) (0.7.5)\n",
            "Requirement already satisfied: unicodecsv in /usr/local/lib/python3.6/dist-packages (from epitran) (0.14.1)\n",
            "Requirement already satisfied: panphon>=0.16 in /usr/local/lib/python3.6/dist-packages (from epitran) (0.17)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from epitran) (45.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from epitran) (2019.12.20)\n",
            "Requirement already satisfied: munkres in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (1.1.2)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (0.5.3)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from panphon>=0.16->epitran) (1.18.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from panphon>=0.16->epitran) (3.13)\n",
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.6)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.28.1)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sklearn_crfsuite) (1.14.0)\n",
            "Requirement already satisfied: tensorflow in /tensorflow-2.1.0/python3.6 (2.1.0)\n",
            "Requirement already satisfied: deepcut in /usr/local/lib/python3.6/dist-packages (0.7.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.1.0/python3.6 (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.26.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (3.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (1.18.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.1.0/python3.6 (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from deepcut) (0.25.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from deepcut) (0.22.1)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (from deepcut) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (45.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->deepcut) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepcut) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->deepcut) (0.14.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.1.0/python3.6 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /tensorflow-2.1.0/python3.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.1.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u3BdH34_hN1",
        "colab_type": "text"
      },
      "source": [
        "Restart Runtime เพื่อให้ใช้ Library เวอร์ชัน ที่เพิ่ง Install ลงไป"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86CaxdqnE0Ag",
        "colab_type": "text"
      },
      "source": [
        "ในเคสนี้ เราจะปิด Warning ไว้ก่อน จะได้อ่านผลลัพท์ง่าย"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rha7sfRokmVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3VxLNfAElR29"
      },
      "source": [
        "# 1. Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nGm02SG0CQrq"
      },
      "source": [
        "Import Library ที่จะใช้ ในที่นี้คือ PyThaiNLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUurvnGIsEWv",
        "colab_type": "code",
        "outputId": "b42ce6aa-142d-4ec2-9722-64946646a37c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pythainlp\n",
        "\n",
        "pythainlp.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeJuPfAjSGnt",
        "colab_type": "text"
      },
      "source": [
        "# 2. PyThaiNLP ตัดคำภาษาไทย"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wv5jznJ84lZ",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 word_tokenize ตัดคำ Word, Sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMMqgQz_4sHr",
        "colab_type": "text"
      },
      "source": [
        "ฟังก์ชันตัดคำของ PyThaiNLP ถูกออกแบบมาให้รองรับหลายอัลกอริทึม เช่น \n",
        "\n",
        "* newmm - Dictionary-based Thai Word Segmentation using maximal matching algorithm and Thai Character Cluster (TCC)\n",
        "* longest - Dictionary-based longest-matching Thai word segmentation\n",
        "* multi_cut - Multi cut – Thai word segmentation with maximum matching\n",
        "* pyicu - Wrapper for PyICU word segmentation. This wrapper module uses icu.BreakIterator with Thai as icu.Local to locate boundaries between words from the text.\n",
        "* deepcut - Wrapper for deepcut Thai word segmentation. deepcut is a Thai word segmentation library using Deep Neural, specifically, 1D Convolution Neural Network.\n",
        "* tcc - The implementation of tokenizer accorinding to Thai Character Clusters (TCCs) rules purposed by Theeramunkong et al. 2000.\n",
        "* etcc - Enhanced Thai Character Cluster (ETCC) Python implementation by Wannaphong Phatthiyaphaibun (19 June 2017)\n",
        "\n",
        "โดยอัลกอริทึมใหม่ล่าสุด และเป็น Default ของ PyThaiNLP tokenize ณ ขณะนี้ คือ newmm ที่ใช้ อัลกอริทึม หา maximum matching จากใน Dictionary ที่ทำงานได้อย่างรวดเร็ว และถูกต้องพอสมควร"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbViFYbf6rzl",
        "colab_type": "text"
      },
      "source": [
        "เราจะ Import sent_tokenize ที่ตัดคำจาก Space, Full stop, New line เหมือนที่ใช้ในภาษาอังกฤษ และ word_tokenize พระเอกของเรา ฟังก์ชันตัดคำภาษาไทย"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTbxnjo4dj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp import sent_tokenize, word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "324GpTe-7J_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"เมืองเชียงรายมีประวัติศาสตร์อันยาวนาน        เป็นที่ตั้งของหิรัญนครเงินยางเชียงแสน\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqEqLApI7KNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "44bd05c8-fb77-4461-c8ca-0cf9aaef664f"
      },
      "source": [
        "print(\"sent_tokenize:\", sent_tokenize(text))\n",
        "print(\"word_tokenize:\", word_tokenize(text))\n",
        "print(\"no whitespace:\", word_tokenize(text, keep_whitespace=False))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sent_tokenize: ['เมืองเชียงรายมีประวัติศาสตร์อันยาวนาน', 'เป็นที่ตั้งของหิรัญนครเงินยางเชียงแสน']\n",
            "word_tokenize: ['เมือง', 'เชียงราย', 'มี', 'ประวัติศาสตร์', 'อัน', 'ยาวนาน', '        ', 'เป็นที่ตั้ง', 'ของ', 'หิรัญ', 'นคร', 'เงิน', 'ยาง', 'เชียงแสน']\n",
            "no whitespace: ['เมือง', 'เชียงราย', 'มี', 'ประวัติศาสตร์', 'อัน', 'ยาวนาน', 'เป็นที่ตั้ง', 'ของ', 'หิรัญ', 'นคร', 'เงิน', 'ยาง', 'เชียงแสน']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8iIx0mM7Kas",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 เปรียบเทียบตัดคำภาษาไทย ด้วยอัลกอริทึมต่าง ๆ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYm_YkkX7Kyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"งานเทศกาลลิ้นจี่และของดีเมืองเชียงราย เทศกาลที่ชาวเกษตรกรต่างนำผลผลิตทางการเกษตรของตนมาออกร้าน โดยเฉพาะลิ้นจี่ที่มีชื่อเสียงมากของเชียงราย \""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Cx6qz-9pHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "302e493d-a39c-4441-ceab-d66df00445d7"
      },
      "source": [
        "print(\"newmm    :\", word_tokenize(text))  # default engine is \"newmm\"\n",
        "print(\"longest  :\", word_tokenize(text, engine=\"longest\"))\n",
        "print(\"multi_cut:\", word_tokenize(text, engine=\"multi_cut\"))\n",
        "print(\"pyicu    :\", word_tokenize(text, engine=\"pyicu\"))\n",
        "print(\"deepcut  :\", word_tokenize(text, engine=\"deepcut\"))\n",
        "print(\"tcc      :\", word_tokenize(text, engine=\"tcc\"))\n",
        "print(\"etcc     :\", word_tokenize(text, engine=\"etcc\"))\n",
        "print(\"ulmfit   :\", word_tokenize(text, engine=\"ulmfit\"))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "newmm    : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "longest  : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทางการ', 'เกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "multi_cut: ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทางการเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียงมาก', 'ของ', 'เชียงราย', ' ']\n",
            "pyicu    : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "deepcut  : ['งาน', 'เทศกาล', 'ลิ้นจี่', 'และ', 'ของ', 'ดี', 'เมืองเชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผล', 'ผลิต', 'ทาง', 'การ', 'เกษตร', 'ของ', 'ตน', 'มา', 'ออก', 'ร้าน', ' ', 'โดย', 'เฉพาะ', 'ลิ้นจี่', 'ที่', 'มี', 'ชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "tcc      : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "etcc     : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n",
            "ulmfit   : ['งานเทศกาล', 'ลิ้นจี่', 'และ', 'ของดี', 'เมือง', 'เชียงราย', ' ', 'เทศกาล', 'ที่', 'ชาว', 'เกษตรกร', 'ต่าง', 'นำ', 'ผลผลิต', 'ทาง', 'การเกษตร', 'ของ', 'ตน', 'มา', 'ออกร้าน', ' ', 'โดยเฉพาะ', 'ลิ้นจี่', 'ที่', 'มีชื่อเสียง', 'มาก', 'ของ', 'เชียงราย', ' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MAtpZ2N-PRA",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 เพิ่มคำใน Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp3YNqhTHvwr",
        "colab_type": "text"
      },
      "source": [
        "ในกรณีที่ข้อความของเรา มีคำแปลก ๆ ที่ไม่มีใน Dictionary ทั่วไป เราสามารถเพิ่มคำเหล่านั้น เข้าไปใน Dictionary ที่ใช้ตัดคำได้ดังตัวอย่างด้านล่าง"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMDWRfINFwl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizer??\n",
        "# thai_words??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3srPNMNDZLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f0f3f2f3-9ce0-4bd9-9ddc-0b6bbeaed399"
      },
      "source": [
        "from pythainlp import word_tokenize, Tokenizer\n",
        "from pythainlp.tokenize import dict_trie\n",
        "from pythainlp.corpus.common import thai_words\n",
        "\n",
        "text = \"เป็งปุ๊ด หรือ เพ็ญพุธ เป็นประเพณีตักบาตรเที่ยงคืนค่อนรุ่งเข้าสู่วันเพ็ญขึ้น15 ค่ำที่ตรงกับวันพุธ ตามวัฒนธรรมและความเชื่อของบรรพบุรุษล้านนาไทย\"\n",
        "\n",
        "print(\"newmm  :\", word_tokenize(text))  # default engine is \"newmm\"\n",
        "print(\"longest:\", word_tokenize(text, engine=\"longest\"))\n",
        "\n",
        "\n",
        "# words = [\"เป็งปุ๊ด\", \"เพ็ญพุธ\"]\n",
        "custom_words_list = set(thai_words())\n",
        "custom_words_list.add('เป็งปุ๊ด')\n",
        "custom_words_list.add('เพ็ญพุธ')\n",
        "trie = dict_trie(dict_source=custom_words_list)\n",
        "\n",
        "custom_tokenizer = Tokenizer(custom_dict=trie, engine='newmm')\n",
        "\n",
        "print(\"custom :\", custom_tokenizer.word_tokenize(text))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "newmm  : ['เป็ง', 'ปุ๊', 'ด', ' ', 'หรือ', ' ', 'เพ็ญ', 'พุธ', ' ', 'เป็น', 'ประเพณี', 'ตักบาตร', 'เที่ยงคืน', 'ค่อน', 'รุ่ง', 'เข้าสู่', 'วันเพ็ญ', 'ขึ้น', '15', ' ', 'ค่ำ', 'ที่', 'ตรง', 'กับ', 'วัน', 'พุธ', ' ', 'ตาม', 'วัฒนธรรม', 'และ', 'ความเชื่อ', 'ของ', 'บรรพบุรุษ', 'ล้านนา', 'ไทย']\n",
            "longest: ['เป็ง', 'ปุ๊', 'ด', ' ', 'หรือ', ' ', 'เพ็ญ', 'พุธ', ' ', 'เป็น', 'ประเพณี', 'ตักบาตร', 'เที่ยงคืน', 'ค่อน', 'รุ่ง', 'เข้าสู่', 'วันเพ็ญ', 'ขึ้น', '15', ' ', 'ค่ำ', 'ที่', 'ตรง', 'กับ', 'วัน', 'พุธ', ' ', 'ตาม', 'วัฒนธรรม', 'และ', 'ความเชื่อ', 'ของ', 'บรรพบุรุษ', 'ล้านนา', 'ไทย']\n",
            "custom : ['เป็งปุ๊ด', ' ', 'หรือ', ' ', 'เพ็ญพุธ', ' ', 'เป็น', 'ประเพณี', 'ตักบาตร', 'เที่ยงคืน', 'ค่อน', 'รุ่ง', 'เข้าสู่', 'วันเพ็ญ', 'ขึ้น', '15', ' ', 'ค่ำ', 'ที่', 'ตรง', 'กับ', 'วัน', 'พุธ', ' ', 'ตาม', 'วัฒนธรรม', 'และ', 'ความเชื่อ', 'ของ', 'บรรพบุรุษ', 'ล้านนา', 'ไทย']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ZXocFREA-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}